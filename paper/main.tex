\documentclass[14pt,russian]{extreport}
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
%\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\geometry{verbose,tmargin=2.1cm,bmargin=2.1cm,lmargin=3cm,rmargin=2cm}
%\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{babel}
\usepackage{color}
\usepackage[hidelinks]{hyperref}
\usepackage{natbib}
%\usepackage{authordate1-4}
%\bibliographystyle{authordate1}
\bibliographystyle{unsrt}
\usepackage{amsmath}
\newtheorem{hyp}{Гипотеза}
\usepackage{graphicx}
\graphicspath{{/home/moskupols/repos/mipt/osm-toponyms/pics/}{pics/}}
\usepackage{float}
\usepackage{placeins}
\usepackage{chngcntr}
\usepackage{braket}
\usepackage{listings}
\usepackage{caption}
\counterwithout{figure}{chapter}
\counterwithout{table}{chapter}

%\onehalfspacing
\linespread{1.4}

% remove chapter number from section headings
\renewcommand*\thesection{\arabic{section}}

% rename chapters
\makeatletter
\renewcommand{\@chapapp}{Часть}
\makeatother

% continuous equation numbering through chapters
\usepackage{chngcntr}
\counterwithout{equation}{chapter}

\usepackage{indentfirst}
\frenchspacing

\newcommand{\todo}{{\color{red}[\,!\,]}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% \sloppy
% \fussy

\begin{titlepage}
\begingroup
	\centering
	{\scshape
	\fontsize{12pt}{14pt}\selectfont Министерство образования и науки Российской Федерации\par
	\vspace{0.7cm}
	Государственное образовательное учреждение \\высшего профессионального образования\par
	Московский физико-технический институт\\(государственный университет)\par
	\vspace{0.7cm}
	Факультет инноваций и высоких технологий\par
	Кафедра компьютерной лингвистики\par
	\vspace{0.7cm}
	\fontsize{14pt}{17pt}\selectfont выпускная квалификационная работа\\(бакалаврская работа)\par}
	\fontsize{14pt}{17pt}\selectfont по направлению 01.03.02 «Прикладная математика и информатика»\par
	\vspace{1cm}
	{\fontsize{21pt}{25pt}\selectfont\bfseries Топонимы и OpenStreetMap\par}
	\vspace{4cm}
	
	\begin{tabular}{l@{\hspace{140pt}}r}
      Студент & Алексеев Ф.М. \\
      Научный руководитель & Новицкий В.И.
	\end{tabular}
	\par
	\vfill

	{\fontsize{14pt}{17pt}\selectfont Москва, 2017\par}
\endgroup
\end{titlepage}

\clearpage
\addtocounter{page}{1}
\tableofcontents{}

\pagebreak{}

\chapter{Введение}

\section{Обзор предметной области}

Извлечение именованных сущностей\cite{nadeau2007survey} (Named Entity
Recognition)~--- важная подзадача во многих задачах, требующих автоматического
извлечения структурированной информации из текста на естественном
языке\cite{feldman2007text}. Примеры таких задач включают информационный поиск,
вопросно-ответные системы, автоматизированный сбор новостей. Под именованной
сущностью (Named Entity) здесь мы понимаем объект, имеющий имя или название и
относящийся к определённому типу, такому как, например, личности, организации,
географические объекты и другие.

\paragraph{Подходы к извлечению именованных сущностей}

Множество алгоритмов извлечения именованных сущностей можно разбить на три
основных класса:
\begin{itemize}
  \item Подходы, основанные по большей части на словарях, то есть списках
    известных именованных сущностей. Основными недостатками этих подходов
    называют неустойчивость к омонимии и к упоминанию в тексте объектов,
    неизвестных составителям словаря.
  \item Подходы, основанные на составленных вручную правилах. Такие подходы
    часто требуют от разработчиков обширных познаний в грамматике языка и
    ориентированы на ограниченное множество языков. Существует множество мощных
    программных решений, обеспечивающих разработку и отладку систем правил,
    таких как Apache UIMA\cite{uima,uima-ruta} и GATE\cite{Cunningham2010}. Нужно заметить, что системы правил
    используются не только для извлечения именованных сущностей, но и для более
    общего анализа текста.
  \item Подходы, основанные на машинном обучении. Такие подходы как правило
    требуют для обучения некоторого корпуса уже размеченных текстов, и их
    эффективность может зависеть от объёма и качества этого корпуса. В разное
    время наиболее популярными методами машинного обучения, применяющимися для
    извлечения именованных сущностей, можно было назвать скрытые марковские
модели(Hidden Markov Models, HMM)\cite{mccallum2000maximum}, решающие деревья
(Decision Tree, DT)\cite{szarvas2006multilingual} и их ансамбли, условные
случайные поля(Conditional Random Field, CRF)\cite{crfusage}, опорных
векторов(Support Vector Machine, SVM)\cite{isozaki2002efficient}, рекуррентные
нейросети (Recurrent Neural Network, RNN)\cite{li2015biomedical}, свёрточные
нейросети (Convolutional
Neural Network, CNN)\cite{chiu2015named}.
\end{itemize}

\paragraph{Факторы, влияющие на системы извлечения именованных сущностей}

При разработке систем извлечения именованных сущностей следует учитывать
следующие факторы, рассмотренные в \cite{nadeau2007survey}:

\begin{itemize}
  \item Языковой фактор

    При разработке систем извлечения именованных сущностей для конкретного
    языка учитываются его особенности. Например, в английском языке тексты
    читаются слева направо, а к именованным сущностям часто относятся имена
    собственные, которые пишутся с заглавной буквы. Однако нельзя применять те
    же методы к таким языкам, как фарси, идиш, иврит, где чтение ведется справа
    налево, а в начале имен собственных нет заглавных букв.

  \item Жанры и предметные области текстов

    Тексты относятся к разным стилям речи (публицистический, научный,
    разговорный), посвящены разным областям (например, политика, медицина,
    наука, экономика, спорт). Особенности стилей и предметных областей
    учитываются в системах извлечения именованных сущностей, специализированных
    на конкретных типах текстов. Примерами таких типов являются электронные
    письма, научные статьи, новостные заметки, религиозные тексты, записи
    телефонных разговоров и другие. Экспериментально установлено, что система,
    хорошо работающая с текстами определенного типа, показывает худшие
    результаты при обработке текстов другого типа.

  \item Типы именованных сущностей.

    К основным типам именованных сущностей обычно относят PERSON, ORGANIZATION,
    LOCATION. На конференции MUC-6 их объединили в категорию Enamex. Также на
    MUC рассматриваются категории Timex, которая включает типы «время», «дата»,
    и Numex, которая включает типы «денежное выражение», «процентное
    выражение».

    В зависимости от предметных областей и приложений системы извлечения
    именованных сущностей могут добавляться новые типы именованных сущностей.
\end{itemize}

Эта работа фокусируется на извлечении из текста конкретного типа именованных
сущностей~--- топонимов, то есть имён собственных, обозначающих определённый
географический объект. Одна из трудностей в решении этой задачи заключается в
относительно часто встречающейся омонимии между топонимами и другими именами
собственными, в первую очередь именами людей, а также то, что в текстах разных
стилей топониму могут быть использованы по-разному, скажем, в разговорной речи
многие ключевые слова, способствующие снятию омонимии, могут быть опущены.
Предполагается, что вывод классификатора, разработанного в ходе этой работы,
будет пригоден к использованию уже при разрешении неоднозначностей при
синтаксическом разборе текста, поэтому будут использоваться только локальные
признаки слов, такие как морфологическое значение и факт нахождения в словарях
и газетирах, а также соответствующие признаки соседних слов.

\section{Постановка задачи}

Задача данной дипломной работы состоит в разработке метода извлечения
топонимических объектов, который использует только локальную информацию о
словах в тексте.

Для этого требуется:
\begin{itemize}
  \item Исследовать существующие методы извлечения именованных сущностей и
    топонимов;

  \item Разработать метод извлечения топонимов из естественного текста на
    русском языке на примере названий городов и улиц. В качестве обучающей
    выборки использовать результат автоматической разметки новостного корпуса
    инструментами ABBYY Compreno.

  \item Подготовить размеченный вручную тестовый корпус;

  \item Провести тестирование качества разработанного метода и анализ ошибок.
\end{itemize}

\chapter{Ручная и автоматическая разметка}

\section{Ручная разметка}

В качестве обучающего и тестового корпусов была выбрана подборка текстов,
включающая в себя новостные статьи на русском языке из различных источников.

Тестовый корпус, состоящий из 300 случайно выбранных документов из этой
подборки, был размечен вручную.

В дальнейших иллюстрациях части текста, которые были вручную размечены как
топонимы, будут подчёркнуты.
Пример: ``Бытовой газ взорвался в четверг днем на третьем этаже жилого дома на
\underline{Кутузовском проспекте}''.

\section{Структура автоматической разметки}

Тексты обучающего и тестового корпусов были размечены с помощью инструментов
ABBYY Compreno\cite{anisimovich2012syntactic}, таким образом были получены аннотации всех вхождений в текст
сущностей классов CITY\_TOWN (город, населённый пункт и т.п.) и PUBLIC\_ROAD
(улица, трасса, набережная и т.п.). Разметка получена в формате
xml-документов(RDF), в которых размечаемый текст помещён без изменений, а все
аннотации помещены в отдельные теги, и привязаны к позициям в тексте при помощи
указанных в атрибутах этих тегов отступов от начала текста.

Классификатор, который будет описан в этой работе, обрабатывает текст, разбивая
его на токены и приписывая каждому токену некоторые признаки, отбрасывая при
этом информацию о точной позиции слова в документе. Поэтому чтобы связать
данные автоматической разметки с токенами, на уровне которых оперирует
классификатор, необходимо дополнительное преобразование.

Для этого представим все аннотации в виде пар (начало промежутка, конец
промежутка), и организуем лексикографически отсортированный по этим парам
список всех аннотаций в документе. Теперь, если представить каждый токен в виде
аналогичной пары, предикат ``токен проаннотирован'' можно переформулировать в
виде ``промежуток токена находится внутри промежутка аннотации''. Благодаря
тому, что список отсортирован, можно воспользоваться алгоритмами двух
указателей или бинарного поиска, что позволит добиться вычислительной сложности
разбора документа соответственно $O(n)$ или $O(n \log m)$, где $n$~--- длина
текста, $m$~--- число аннотаций. Более простой в реализации алгоритм имел бы
сложность $O(nm)$, которая была бы заметна при чтении больших текстов, в
которых упоминается множество топонимов.

В дальнейших примерах части текста, которые были автоматически проаннотированы
как топонимы, будут выделены курсивом.
Пример: ``Бытовой газ взорвался в четверг днем на третьем этаже жилого дома на
\underline{\it Кутузовском проспекте}''.

\section{Инструменты оценки качества классификатора}

Перед нами стоит задача бинарной классификации. Нам дано некоторое множество
объектов $X$, ассоциированное с вектором истинных классов этих объектов
$y_{true}$. Пусть некоторый классификатор по этому множеству объектов выдаёт
вектор ответов $y_{pred}$. Как оценить качество ответов этого классификатора?

Разобъём множество объектов на 4 типа:

\begin{itemize}
  \item True Positive (TP) = $\set{x \in X | y_{true}(x) \land y_{pred}(x)}$,
    то есть объекты, верно отнесённые к положительному классу;
  \item True Negative (TN) = $\set{x \in X | \neg y_{true}(x) \land \neg
    y_{pred}(x)}$, то есть объекты, верно отнесённые к отрицательному классу;
  \item False Positive (FP) = $\set{x \in X | \neg y_{true}(x) \land
    y_{pred}(x)}$, то есть объекты, неверно отнесённые к положительному классу;
  \item False Negative (FN) = $\set{x \in X | y_{true}(x) \land \neg
    y_{pred}(x)}$, то есть объекты, неверно отнесённые к отрицательному классу.
\end{itemize}

Для оценки качества работы алгоритма введём метрики Precision (точность) и
Recall (полнота) следующим образом:

$$
  Precision=\frac{|TP|}{|TP| + |FP|}
$$
$$
  Recall=\frac{|TP|}{|TP| + |FN|}
$$

Precision можно интерпретировать как долю объектов, названных классификатором
положительными и при этом действительно являющимися положительными, а Recall
показывает, какую долю объектов положительного класса из всех объектов
положительного класса нашёл алгоритм.

Отметим, что точность и полнота не зависят от соотношения размеров классов.
Даже если объектов положительного класса на порядки меньше, чем объектов
отрицательного класса, данные показатели будут корректно отражать качество
работы алгоритма.

Существует несколько способов получить один критерий качества на основе
точности и полноты. Один из них~— F-мера, гармоническое среднее точности и
полноты:
$$
F = \frac{2 * Precision * Recall}{Precision + Recall}
$$

Среднее гармоническое обладает важным свойством — оно близко к нулю, если хотя
бы один из аргументов близок к нулю. Именно поэтому оно является более
предпочтительным, чем среднее арифметическое (если алгоритм будет относить все
  объекты к положительному классу, то он будет иметь Recall = 1 и Precision
  $\ll$ 1, а их среднее арифметическое будет больше $\frac12$, что
недопустимо).

\section{Анализ ошибок автоматической разметки}

К сожалению, автоматическая разметка не полностью совпадает с ручной. Изучив
примеры ошибок автоматической разметки, их можно приблизительно разбить на
несколько типов:

\begin{enumerate}
  \item \label{izhorsky} Слово, образованное от топонима, аннотировано
    неотличимо от самого этого топонима. Примеры: ``Проект {\it ижорского}
    броневика-копии был создан специалистами КБ-3.'', ``В {\it новосибирской}
    мэрии первоначально планировали разместить там традиционные фигуры Деда
    Мороза.''

  \item \label{dzerzh} Помечено слово, омонимичное известному топониму. Пример
    из текста про Балашиху: ``В микрорайоне {\it Дзержинского} в доме 35 был
    подтоплен подвал.''

  \item \label{poselok} Помечено только ключевое слово, такое как ``посёлок'',
    когда речь не идёт о каком-то конкретном посёлке. Пример: ``Это первый {\it
    поселок}, строительство в котором началось еще до старта продаж.''

  \item \label{inn} Помечено слово, не имеющее отношения к топонимам, например,
    ``{\it ИНН}''.

  \item \label{bolotnaya} Не аннотирован топоним, употреблённый без ключевого
    слова, такого как ``город'' или ``улица''. Примеры: ``Как тут не вспомнить
    абсолютно искреннюю \underline{Болотную}, куда по факту получения твита шли
    целые фирмы офисных лодырей.'', ``В \underline{Кашиас-ду-Сул} массовые
    протесты собрали около 10 тысяч человек.''

  \item \label{meschera} Улица или город не аннотированы, несмотря на явное
    наличие связанного слова, указывающего на то, что это топоним. Примеры:
    ``Жена его, забрав детей, сбежала от такой жизни в \underline{село
    Мещерское}, работать фельдшерицей в психиатрической лечебнице.''

  \item \label{sosnoviy} Неверно выделены границы топонима, состоящего из
    нескольких слов, из-за чего часть этих слов помечены верно, а часть — нет.
    Пример: ``\dotsследующих из \underline{{\it города} Сосновый {\it Бор}}
    Ленобласти\dots''
\end{enumerate}

В таблице \ref{tab:auto-errors} приведены количественные и процентные отношения
для каждого типа ошибок.

\begin{table}[p]
  \centering
  \begin{tabular}{l|rrr}
    Тип ошибки & \# ошибок & \% ошибок & \% корпуса \\
    \hline
    \ref{izhorsky} (``{\it ижорского}'') & 217 & 20.07\% & 0.52\%  \\
    \ref{dzerzh} (``в микрорайоне {\it Дзержинского}'') & 15 & 1.39\% & 0.04\%  \\
    \ref{poselok} (``это первый {\it посёлок}'') & 50 & 4.63\% & 0.12\%  \\
    \ref{inn} (``{\it ИНН}'') & 14 & 1.3\% & 0.03\%  \\
    \ref{bolotnaya} (``искреннюю \underline{Болотную}'') & 426 & 39.41\% & 1.03\%  \\
    \ref{meschera} (``\underline{село Мещерское}'') & 260 & 24.05\% & 0.63\%  \\
    \ref{sosnoviy} (``из \underline{ {\it города} Сосновый {\it Бор} }'') & 99 & 9.16\% & 0.24\%  \\
    \hline
    Итого & 1081 & & 2.62\%
  \end{tabular}
  \caption{Процентные отношения для каждого типа ошибок автоматической разметки}
  \label{tab:auto-errors}
\end{table}

Если принять ручную разметку за истину, Precision автоматической разметки
приблизительно равен 0.85, Recall 0.73. В таблицах \ref{tab:auto-quad},
\ref{tab:auto-quad-norm} представлена матрица неточностей (confusion matrix)
для ручной и автоматической разметок.

\begin{table}[p]
  \centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{r|cc}
    &        Positive         & Negative \\
    & автоматической разметки & автоматической разметки \\
    \hline
    Positive ручной разметки & 4.9\% & 1.8\%  \\
    Negative ручной разметки & 0.8\% & 92.5\% \\
\end{tabular}}
  \caption{Нормированная матрица неточностей для автоматической разметки}
  \label{tab:auto-quad}
\end{table}

\begin{table}[p]
  \centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{r|cc}
    &        Positive         & Negative \\
    & автоматической разметки & автоматической разметки \\
    \hline
    Positive ручной разметки & 2011 & 736   \\
    Negative ручной разметки & 345  & 38246 \\
\end{tabular}}
  \caption{Матрица неточностей для автоматической разметки}
  \label{tab:auto-quad-norm}
\end{table}

\chapter{Построение решения}

\section{Токенизация}

Задача токенизации текста, то есть разбиения его на слова актуальна\cite{2014nkra,2016kvoprosu,2012opencorpora} по сей день,
несмотря на кажущуюся простоту.
На практике определение границ слов редко можно свести к разбиению строки на
подстроки между пробельными символами или местами, где буквы сменяются цифрами
или знаками пунктуации.
Как правило, конкретный способ токенизации необходимо подбирать из специфики
задачи, которая будет решаться с использованием полученных токенов.
Токенизация может сильно отличаться для разных языков и стилей текста: скажем,
в литературном тексте может быть менее важно правильно токенизировать
десятичные дроби, чем в школьном учебнике по математике, зато куда важнее верно
токенизировать имена и топонимы, не путая дефисы в названии города или улицы с
минусами.

Качественный токенизатор особенно важен потому, что находится в самом начале
последовательности инструментов, анализирующих текст. Возможные дальнейшие
морфологические, синтаксические и семантические анализаторы полагаются на
корректное разбиение текста на токены, и их качество напрямую зависит от этого
разбиения.

В работе \cite{rus_tokenization} описывается сложная система токенизации
для русского языка, основанная на правилах, способная устранять неоднозначности
из контекста. Качество работы этой системы сравнивается с более простым
алгоритмом TokTok, входящим в состав библиотеки NLTK\cite{Loper:2002:NNL:1118108.1118117}, и основанном на наборе
регулярных выражений. Согласно этой статье, даже на специально подобранном
корпусе TokTok показывает качество от 98\% f-меры, близкое к качеству
предлагаемой сложной системы. В этой работе мы тоже будем использовать алгоритм
TokTok ввиду его доступности и популярности как токенизатора русского языка.

Тем не менее, TokTok предполагает, что ему на вход подаётся строка, содержащая
одно предложение текста, так что все точки внутри этой строки скорее всего
должны быть отнесены к соседнему слову, так как возможно обозначают не конец
предложения, а, например, сокращение. Поэтому для выделения предложений в
тексте мы используем ещё один инструмент из библиотеки NLTK,
PunktSentenceTokenizer, представляющий из себя некоторую заранее обученную
статистическую модель.

Таким образом, токенизация текста для нашего классификатора теперь состоит из
последовательного применения двух инструментов из библиотеки NLTK:
PunktSentenceTokenizer и TokTok.

Однако специфика задачи требует немного скорректировать полученную конструкцию.
Дело в том, что TokTok не разделяет слово из букв и одиночных точек на
несколько токенов. Например, строка ``ул.Верхоянская'' (без пробелов) будет
представлена одним токеном. Для классификатора же было бы важно разделить эту
строку на два токена: ``ул.'' (ключевое слово, наверняка составляющее часть
топонима) и ``Верхоянская'' (топоним, который наверняка можно найти в
газетире).
Поэтому каждый токен, полученный на выходе TokTok, и содержащий в себе точку,
будем разбивать на более мелкие токены, используя для этого регулярное
выражение
\begin{verbatim}[^.]+\.?\end{verbatim} в синтаксисе модуля re языка
программирования python.

\section{Признаковое пространство}

В этой главе будут подробно описаны признаки, извлекаемые из каждого токена, и
используемые классификатором для определения топонимов в тексте, а также
процесс их извлечения.

Все эти признаки можно назвать локальными в том смысле, что они считаются для
каждого токена в отдельности, независимо от соседних токенов, его позиции
в предложении и его позиции в документе. Двум посимвольно равным токенам будет
соответствовать одинаковый вектор признаков.

\subsection{Морфологические признаки}

Важное свойство русского языка, отличающее его от, например, английского,
состоит в богатой морфологии. Морфологический разбор каждого слова ценен при
анализе структуры предложения. Поэтому мы будем использовать в качестве
признаков грамматическое значение слова в предположении, что языковые
конструкции, использующие топонимы, часто похожи грамматически.

Для морфоанализа будем использовать библиотеку
pymorphy2\cite{pymorphy2}. Основная идея, используемая в этой библиотеке,~---
разбиение всех слов языка на классы с одинаковой грамматической парадигмой.
Имея такое разбиение, задачу определения грамматического значения данного слова
можно свести к определению его парадигмы. Это можно сделать с помощью конечных
автоматов, анализирующих начало и конец слова.

В качестве корпуса, содержащего слова с известными грамматическими значениями,
в pymorphy2 используется OpenCorpora. Но даже слово, которого нет в
OpenCorpora, может быть правильно разобрано с помощью pymorphy2, если удастся
определить его парадигму. Эта возможность особенно полезна при определении
грамматического значения имён собственных.

Если существует несколько возможных грамматических значений, соответствующих
одной форме слова, pymorphy2 выдаст их все, снабдив эмпирической частотой
использования каждого варианта в OpenCorpora.

Вектор морфологических признаков токена $v_{morph}$ мы получим следующим
образом. Пусть анализатор pymorphy2 выдал для данного токена множество
возможных грамматических значений $\set{g_i}$ с эмпирическими частотами
$\set{w_i}$. Тогда $$v_{morph} = \sum g_i * w_i.$$ Таким образом, $v_{morph}$~---
это не грамматическое значение слова, а скорее вектор, в каждой компоненте
которого содержится оценка вероятности того, что данное слово соответствует
некоторой грамматической категории.

Подобный способ работы с неоднозначностью морфологического разбора будет
использован при извлечении признаков, описанных далее, и использующих
лемматизацию, которая также выполняется при помощи pymorphy2.

\subsection{Шаблон капитализации}

Ещё одно свойство русского языка, отличающее его от, например, немецкого,~---
то, что нарицательные в середине предложения как правило пишутся со строчной
буквы, тогда как имена собственные по правилам всегда пишутся с заглавной
буквы. Конечно, на практике это наблюдение выполняется не всегда, и не всякое
имя собственное является топонимом, тем не менее, капитализация~--- простой в
реализации признак, который во многих задачах даёт улучшение качества\cite{Ritter:2011:NER:2145432.2145595}.

Кроме регистра первой буквы токена бывает также полезно проверить капитализацию
всех букв слова: если слово состоит только из заглавных букв, наверняка это
аббревиатура, обозначающая некоторую именованную сущность.

Таким образом, вектор признаков капитализации для данного токена будет состоять
из трёх компонент, отражающих, начинается ли слово с заглавной буквы, состоит
ли оно полностью из заглавных букв, и состоит ли оно полностью из строчных
букв.

\subsection{Словарные признаки}

Так как специфика решаемой задачи вполне определена и известна, в качестве
части признаков можно использовать специально подобранные словари. Так как
классификатор не будет полагаться только на них, он не выродится в тривиальный
алгоритм извлечения сущностей, работающий только на словарях. Тем не менее, в
неоднозначных случаях факт принадлежности токена тому или иному словарю может
способствовать верной классификации\cite{cohen2004exploiting}.

Можно придумать много разных специализированных словарей. Для использования
этих словарей в признаках важно понимать, какого размера словари могут
достигать.

Если заранее известно, что размер словаря не превысит некоторого фиксированного
числа, скажем, нескольких сотен, можно использовать модель one-hot encoding, то
есть соотнести с каждым токеном вектор признаков, в $i$-й компоненте которого
будет 1, если токен равен $i$-му слову из словаря, и 0 в противном случае.
Перед поиском в словаре выполним лемматизацию с помощью pymorphy2, и описанным
выше способом будем учитывать частоту каждой леммы.

Для классификатора будем использовать два таких словаря.

Один из словарей будет состоять из вручную отобранного списка ключевых слов,
предположительно имеющих отношение к локациям и топонимам, таких как ``шоссе'',
``река'', ``площадь'', а также различных вариантов их сокращений.

В качестве другого словаря используем лемматизированный частотный словарь
русского языка Шарова\cite{sharoff2002frequency} на основе Национального
корпуса русского языка. Возьмём
из него первые 500 слов. Предполагается, что так как эти слова самые частые,
они покроют значительную часть входного документа, и хотя бы про эту часть
классификатор будет в точности знать, что это за слова.

\subsection{Газетиры}

Так как мы строим классификатор, выделяющий в тексте топонимы, помимо словаря
ключевых слов будем использовать газетиры, то есть словари топонимов. В
качестве источника газетира используем открытую базу географических данных
OpenStreetMap. Эта открытая база данных хранит информацию о городах и улицах,
такую как координаты, форма, население городов, тип покрытия для дорог, и так
далее.

OpenStreetMaps предоставляет интерфейс Overpass, позволяющий выполнить
фильтрацию и обработку данных на стороне сервера базы данных, чтобы затем
получить только нужные данные. Листинг \ref{overpass} содержит пример
Overpass-запроса, описывающего все дороги России, то есть все пути (way),
имеющие тэг ``highway'', у которых при этом указано имя.

\begin{figure}
\begin{lstlisting}[frame=single,caption=Пример Overpass-запроса,label=overpass]
area["ISO3166-1"="RU"];
(
    way
    ["name"]["highway"]
    (area);
);
out;
\end{lstlisting}
\end{figure}

К сожалению, запросы большого количества данных, таких как дороги всей России,
часто заканчиваются неудачей. При подготовке газетиров для экспериментов
пришлось воспользоваться альтернативным способом использования базы
OpenStreetMap. Был скачан дамп всех данных OSM, относящихся к объектам на
территории стран СНГ (так как подавляющее большинство новостей в корпусе
касаются именно территории стран СНГ). Затем с помощью инструмента osmosis была
сделана фильтрация только именованных дорог (way, у которого есть тэги name и highway) и населённых пунктов (node, у которого есть тэги place и name). Полученные
списки имён были использованы как газетиры.

Здесь встаёт вопрос о том, как использовать эти газетиры в признаках. Мы не
можем использовать one-hot encoding для газетиров, так как они содержат
сотни тысяч записей.

Для описываемого классификатора был использован следующий подход.
Изначально вектор признаков заполнен нулями. Затем для каждой леммы слова для
каждого $i$ к $i$-й компоненте вектора добавляется $i*g_i$, где $g_i$~--- число
элементов газетира, для которых лемматизированный токен на позиции $i$
совпадает с этой леммой. Таким образом мы учтём порядок слов в топонимах,
состоящих из нескольких слов.

\subsection{Признаки на основе Word2Vec}

Ещё одна популярная в последнее время альтернатива one-hot encoding~---
Word2Vec\cite{w2v,w2v_expl}.

Word2Vec получает на вход коллекцию текстов и выдаёт представления всех слов из
словаря коллекции в виде вещественного вектора фиксированной невысокой
размерности.

Помимо размерности выходного вектора, важное преимущество Word2Vec перед
one-hot encoding состоит в том, что в Word2Vec учитывается семантическая
близость слов таким образом, что векторы близких слов близки друг к другу по
некоторой мере (например, косинусной)\cite{from_freq}. Это важное свойство,
оно, например, позволяет моделям объединять слова в группы по семантической
близости и оперировать этими группами.

Существует две модели Word2Vec: Continuous Bag-Of-Words и Skip-gram. Они
отличаются архитектурой нейронной сети, используемой для получения векторов, и
обе используют статистику встречаемости пар слов в пределах небольшого
скользящего окна.

Для нашего классификатора используем модель Continuous Bag-Of-Words Word2Vec,
взятую с сайта проекта RusVect\={o}r\={e}s\cite{KutuzovKuzmenko2017}. Модель обучена на корпусе русскоязычных
новостей с сентября 2013 до ноября 2016 года с окном ширины 2 и размерностью
векторов 300. Размер использованного корпуса составляет почти 5 миллиардов
слов, были оставлены только слова, встретившиеся в потоке документов хотя бы
200 раз. Полученный словарь содержит 194058 лемм.

\section{Классификатор на основе экстремального градиентного бустинга}

\subsection{Устройство классификатора}

Идея бустинга состоит в последовательном построении ансамбля элементарных
моделей, для каждой из которых функция потерь подбирается так, чтобы при
добавлении модель компенсировала ошибки уже построенного ансамбля.

В градиентном бустинге каждая следующая элементарная модель приближает
антиградиент функции потерь. Например, если функция потерь среднеквадратичная,
то есть $$ L(y) = \frac12 \sum_i (y_{true,i} - y_{pred,i})^2, $$ то её
антиградиент представляет собой разность между ожидаемыми и предсказанными
значениями, то есть вектор с компонентами вида $$(y_{pred,i} - y_{true,i}).$$

Существует множество вариантов бустинга, использующих разные функции потерь и
разные элементарные модели. В xgboost\cite{chen2016xgboost} используется
логистическая функция потерь и неглубокие решающие деревья в качестве
элементарных моделей. Особенностью реализации бустингового алгоритма в xgboost
является то, что кроме первой, используется также вторая производная функции
потерь, что повышает эффективность алгоритма. Также в xgboost встроена
регуляризация, что оказалось очень важно при построении нашего классификатора.

\subsection{Скользящее окно}

Чтобы классификатор мог анализировать контекст из нескольких подряд идущих
токенов, будем идти по потоку признаковых векторов скользящим окном ширины $W$,
где $W$ нечётное, и подавать на вход классификатора все $W$ векторов,
приписанные подряд один к другому. Таким образом длина признакового вектора,
которым оперирует классификатор, в $W$ раз больше длины признакового вектора,
получаемого из одного токена. Это увеличение длины существенно, так как длина вектора из всех описанных признаков может достигать 790.

При использовании скользящего окна нужно следить за тем, чтобы каждый токен
один раз побывал в середине некоторого скользящего окна, так как классификатор
будет предсказывать метку именно слова в середине окна, по возможности
используя его контекст. Чтобы этого добиться, добавим в начало и в конец потока
признаковых векторов текста по $\frac{W-1}{2}$ нулевых признаковых векторов.
Теперь каждый токен исходного текста будет помещён в середину некоторого
скользящего окна ширины $W$.

Теперь нужно выбрать некоторое оптимальное значение $W$, достаточно большое,
чтобы классификатору хватало контекста в большинстве случаев, но и не слишком
большое, чтобы модель справилась с $790 * W$ признаками. Эксперименты показали,
что увеличение $W$ до значения, большего 5, не улучшает качество классификации
на ручной разметке. В дальнейших экспериментах будет использоваться окно ширины
5. Соответственно, длина признакового вектора приближается к 4000.

\subsection{Подбор параметров}

Используя известные подходы\cite{tunexgb} к подбору параметров для xgboost,
можно получить классификатор, выдающий ответы, очень близкие к автоматической
разметке (f-score 0.97).
Тем не менее, обученный таким образом классификатор показывает худшее качество
на ручной разметке (f-score 0.71), что, по-видимому, следует считать примером
переобучения: классификатор хорошо воспроизводит ошибки автоматической
разметки, а в тех случаях, когда он всё же даёт ответ, отличный от неё, он с
большой вероятностью ошибётся также и в смысле сравнения с ручной разметкой,
так как доля ошибок автоматической разметки небольшая.

После серии экспериментов с регуляризацией я зафиксировал оптимальные параметры
классификатора, приведённые в таблице \ref{tab:params}. С этими параметрами
классификатор выдаёт в среднем лучшее качество на тестовой разметке. Все
эксперименты, описанные далее, воспроизводились с использованием именно этих
параметров.

\begin{table}
  \centering
  \begin{tabular}{l|r}
    Параметр & Значение \\
    \hline
    learning\_rate & 0.05 \\
    n\_estimators & 90 \\
    max\_depth & 6 \\
    min\_child\_weight & 1 \\
    gamma & 0 \\
    subsample & 0.5 \\
    colsample\_bytree & 0.5 \\
    scale\_pos\_weight & 1 \\
  \end{tabular}
  \caption{Параметры xgboost, используемые в классификаторе}
  \label{tab:params}
\end{table}

\subsection{Анализ ошибок}

Так как классификатор обучается на автоматической разметке, мы будем
использовать такую же классификацию ошибок, как для автоматической разметки.
Как видно из таблицы \ref{tab:class-errors}, относительный размер некоторых классов
изменился лишь незначительно.

\begin{table}
  \centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{l|rrrrrr}
    & \multicolumn{3}{c}{xgboost} & \multicolumn{3}{c}{Compreno} \\
    Тип ошибки &
    {\tiny \# ошибок} & {\tiny \% ошибок} & {\tiny \% корпуса} &
    {\tiny \# ошибок} & {\tiny \% ошибок} & {\tiny \% корпуса} \\
    \hline
      \ref{izhorsky} (``{\it ижорского}'') & 165 & 15.87 & 0.40 & 217 & 20.07 & 0.52  \\
      \ref{dzerzh} (``в микрорайоне {\it Дзержинского}'') & 19 & 1.83 & 0.05 & 15 & 1.39 & 0.04  \\
      \ref{poselok} (``это первый {\it посёлок}'') & 43 & 4.13 & 0.10 & 50 & 4.63 & 0.12  \\
      \ref{inn} (``{\it ИНН}'') & 9 & 0.87 & 0.02 & 14 & 1.30 & 0.03  \\
      \ref{bolotnaya} (``искреннюю \underline{Болотную}'') & 413 & 39.71 & 1.00 & 426 & 39.41 & 1.03  \\
      \ref{meschera} (``\underline{село Мещерское}'') & 291 & 27.98 & 0.70 & 260 & 24.05 & 0.63  \\
      \ref{sosnoviy} (``из \underline{ {\it города} Сосновый {\it Бор} }'') & 100 & 9.62 & 0.24 & 99 & 9.16 & 0.24  \\
    \hline
    Итого & 1040 & & 2.58 & 1081 & & 2.62
  \end{tabular}}
  \caption{Размеры классов ошибок предложенного классификатора на основе xgboost и автоматической разметки Compreno}
  \label{tab:class-errors}
\end{table}

\begin{table}
  \centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{r|cc}
    &        Positive   & Negative \\
    & классификации & классификации \\
    \hline
    Positive ручной разметки & 1992 & 755   \\
    Negative ручной разметки & 285  & 38303 \\
\end{tabular}}
  \caption{Матрица неточностей для разметки предложенным классификатором}
  \label{tab:class-quad}
\end{table}

\begin{table}
  \centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{r|cc}
    &        Positive & Negative \\
    & классификации & классификации \\
    \hline
    Positive ручной разметки & 4.8\% & 1.8\%  \\
    Negative ручной разметки & 0.7\% & 92.6\% \\
\end{tabular}}
  \caption{Нормированная матрица неточностей для разметки предложенным классификатором}
  \label{tab:class-quad-norm}
\end{table}

Можно заметить, что общее число ошибок классификатора даже меньше числа ошибок
автоматической разметки, хоть и имеет, впрочем, тот же порядок: 1040 ошибочно
размеченных токенов против 1081. Значит, должны быть предложения, которые
классификатор разметил даже корректнее, чем автоматическая разметка. Приведём
несколько таких примеров (во всех этих примерах курсивом выделены слова,
помеченные автоматической разметкой, и подчёркнуты слова, помеченные ручной
разметкой и классификатором. Различия выделены полужирно.):

\begin{itemize}
  \item ``Место нахождения: 125009, \underline{\it г. Москва}, \underline{\textbf{Средний}
    \it Кисловский переулок}, дом 1/13, строение 8.''
  \item ``Пять домов были разрушены и в \underline{\textit{селе} \textbf{Старая} \textit{Кондрашовка}}, где на момент налета и до него совсем не было вооруженных людей.''
  \item ``Встреча состоялась 4 февраля на \underline{\textbf{Театральной} \textit{площади}} \underline{\textit{Ростова-на-Дону}}.''.
  \item ``11 февраля на \underline{\textbf{Дворцовой} \textit{площади}} \underline{\textit{Лиссабона}} состоялся 300-тысячный митинг.''
\end{itemize}

\subsection{Анализ влияния признаков на качество}

Так как размерность пространства признаков велика, типичный способ оценки
влияния признаков, основанный на присваивании лесом решающих деревьев веса для
каждого признака, малоэффективен.

Мы воспользуемся другим, более общим подходом. Идея состоит в том, чтобы
пронаблюдать, как меняется качество классификации с изменением набора
использованных признаков.

В таблице \ref{tab:feature-sets} отражён состав исследованных наборов
признаков и качество классификации на них. Рисунки
\ref{pic:feature-sets-prec},
\ref{pic:feature-sets-recall}, \ref{pic:feature-sets-f1}
также иллюстрируют изменение качества классификации при изменении набора
используемых признаков.

\begin{table}
\resizebox{\textwidth}{!}{%
  \centering
  \begin{tabular}{r|cccccccccccc}
    & F1 & F2 & F3 & F4 & F5 & F6 & F7 & F8 & F9 & F10 & F11 & F12 \\
    \hline
    Морфология        & +  &    & +  & +  & +  & +  & +  &    & +  & +  &   &  \\
    Капитализация                  & +  & +  &    & +  & +  & +  &    &    &    & +  &  &   \\
    Словари & +  & +  & +  &    & +  & +  &    &    & +  & +  &    &  \\
    Газетир                        & +  & +  & +  & +  &    & +  &    & +  & +  &    & + &  \\
    Word2Vec                       & +  & +  & +  & +  & +  &    &    &    &    &    & + & +  \\
    \hline
    Precision & 0.87 & 0.87 & 0.87 & 0.88 & 0.93 & 0.88 & 0.95 & 0.81 & 0.87 & 0.97 & 0.85 & 0.93 \\
    Recall    & 0.73 & 0.74 & 0.72 & 0.73 & 0.68 & 0.71 &  0.4 &  0.6 & 0.68 & 0.57 & 0.72 & 0.63 \\
    F-score  & 0.79 &  0.8 & 0.79 & 0.79 & 0.79 & 0.78 & 0.56 & 0.69 & 0.76 & 0.71 & 0.78 & 0.75 \\
  \end{tabular}}
  \caption{Состав наборов признаков и качество классификации при их использовании}
  \label{tab:feature-sets}
\end{table}

Хочется отметить несколько любопытных наблюдений:

\begin{itemize}
  \item (наборы F2-F6): удаление только одного типа признаков из пяти не меняет существенно
    f-меру качества классификации.
  \item (наборы F2-F6; F11,F12; F6,F10): удаление только одного типа признаков
    из пяти также не меняет существенно Precision и Recall классификации, кроме
    случая признаков из газетира. По-видимому, из всех признаков газетир
    заметнее всего влияет на точность и полноту классификации.
  \item (набор F8): Тем не менее, модель градиентного бустинга, обученная
    только на газетире, которую можно было бы принять за baseline, показывает
    наихудшее качество в смысле точности, полноты и f-меры, по сравнению с
    моделями, обученными на других наборах, за исключением набора F7,
    использующего только морфологию. Это значит, что признаки из газетира,
    хотя, несомненно, используются моделью и вносят заметный вклад в полноту,
    недостаточны, чтобы воспроизвести качество, близкое к качеству
    классификатора, обученного на более полном наборе признаков. Это указывает
    на то, что модель устойчива к использованию в тексте топонимов,
    отсутствующих в газетире.
  \item (наборы F8,F10): Если отказаться от газетира и использовать только такие
    простые признаки, как морфология, капитализация и конечные словари, можно
    получить лучшую точность, чем при использовании только газетира, и полноту
    того же порядка.
  \item (наборы F6,F11): Word2Vec в сочетании с газетиром даёт качество, очень
    близкое к качеству простых признаков из морфологии, капитализации и
    конечных словарей в сочетании с газетиром.
\end{itemize}

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth]{prec}
  \caption{Точность классификации при разных наборах признаков}
  \label{pic:feature-sets-prec}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth]{recall}
  \caption{Полнота классификации при разных наборах признаков}
  \label{pic:feature-sets-recall}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth]{f1}
  \caption{F-мера классификации при разных наборах признаков}
  \label{pic:feature-sets-f1}
\end{figure}

\chapter{Заключение}

Нам удалось построить классификатор, выделяющий в тексте топонимы городов и
улиц, использующий при этом только локальные признаки токенов и скользящее окно
небольшой ширины 5. Список признаков включает в себя грамматическое значение
слова, его принадлежность различным словарям с использованием разных моделей. С
помощью размеченного вручную корпуса из 300 документов мы исследовали классы
ошибок как автоматической разметки, использованной для обучения, так и
разметки, выводимой классификатором; проанализировали их соотношение.
Эксперименты показали, что построенный классификатор даёт качество на ручной
разметке, близкое к качеству имеющейся до этого автоматической разметки, или
даже лучшее. Мы исследовали влияние отдельных групп признаков на качество
классификации.

\bibliography{report} % bibliography data in report.bib
% \bibliographystyle{spiebib}

\end{document}

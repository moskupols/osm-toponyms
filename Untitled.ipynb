{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.load('data/_mvd.gov.by_16 (nest_id = 48521669).xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Aux = rdflib.Namespace(\"http://www.abbyy.com/ns/Aux#\")\n",
    "ML = rdflib.Namespace(\"http://www.abbyy.com/ns/ML#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#annotation'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#annotation_end'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#annotation_start'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#document_text'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#instance'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#property_name'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/Aux#property_value'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/ML#GenericTerm'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/ML#Name'),\n",
       " rdflib.term.URIRef('http://www.abbyy.com/ns/ML#Type'),\n",
       " rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(g.predicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUBLIC_ROAD\tул.\tГрушевской\t134\t144\n",
      "PUBLIC_ROAD\tул.\tГрушевской\t130\t133\n",
      "CITY_TOWN\tNone\tМинск\t2\t8\n"
     ]
    }
   ],
   "source": [
    "for a in list(g.objects(None, Aux.annotation))[:10]:\n",
    "    inst = g.value(a, Aux.instance)\n",
    "    print(\n",
    "        g.value(inst, ML.Type),\n",
    "        g.value(inst, ML.GenericTerm),\n",
    "        g.value(inst, ML.Name),\n",
    "        g.value(a, Aux.annotation_start),\n",
    "        g.value(a, Aux.annotation_end),\n",
    "        sep='\\t',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "import html\n",
    "import re\n",
    "toktok = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "def tokenize(paragraph, shift=0):\n",
    "    paragraph = paragraph.translate(str.maketrans('«»', '\"\"'))\n",
    "    \n",
    "    begin = end = 0\n",
    "    for sent in nltk.tokenize.sent_tokenize(paragraph):\n",
    "        for ww in toktok.tokenize(sent):\n",
    "            ww = html.unescape(ww)\n",
    "            for w in re.findall('[^.]+\\.?', ww):\n",
    "                try:\n",
    "                    begin = paragraph.index(w, end)\n",
    "                except:\n",
    "                    print(sent)\n",
    "                    print(w)\n",
    "                    raise\n",
    "                end = begin + len(w)\n",
    "                yield {\n",
    "                    'word': w,\n",
    "                    'begin': begin+shift,\n",
    "                    'end': end+shift,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 0, 'end': 1, 'word': 'в'},\n",
       " {'begin': 2, 'end': 6, 'word': '2015'},\n",
       " {'begin': 7, 'end': 9, 'word': 'г.'},\n",
       " {'begin': 10, 'end': 12, 'word': 'мы'},\n",
       " {'begin': 12, 'end': 13, 'word': ','},\n",
       " {'begin': 14, 'end': 16, 'word': 'мы'},\n",
       " {'begin': 17, 'end': 21, 'word': 'всех'},\n",
       " {'begin': 22, 'end': 23, 'word': '('},\n",
       " {'begin': 23, 'end': 27, 'word': 'всех'},\n",
       " {'begin': 27, 'end': 28, 'word': ')'},\n",
       " {'begin': 29, 'end': 30, 'word': '&'},\n",
       " {'begin': 31, 'end': 36, 'word': 'лучше'},\n",
       " {'begin': 38, 'end': 39, 'word': 'А'},\n",
       " {'begin': 40, 'end': 42, 'word': 'вы'},\n",
       " {'begin': 43, 'end': 44, 'word': '—'},\n",
       " {'begin': 45, 'end': 48, 'word': 'нет'},\n",
       " {'begin': 50, 'end': 53, 'word': 'Ул.'},\n",
       " {'begin': 53, 'end': 55, 'word': 'Б.'},\n",
       " {'begin': 55, 'end': 67, 'word': 'Хмельницкого'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenize('в 2015 г. мы, мы всех (всех) & лучше. А вы — нет. Ул.Б.Хмельницкого'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class Annotator:\n",
    "    def __init__(self, annotations):\n",
    "        self.ordered = sorted(annotations)\n",
    "        \n",
    "    def __call__(self, token):\n",
    "        i = bisect.bisect_left(self.ordered, (token['begin'], token['end']))\n",
    "        for a_start, a_end, a in self.ordered[max(0, i-3):i+3]:\n",
    "            if a_start <= token['begin'] and token['end'] <= a_end:\n",
    "                return a\n",
    "            \n",
    "class RdfAnnotator(Annotator):\n",
    "    def __init__(self, g):\n",
    "        super(RdfAnnotator, self).__init__(\n",
    "            [\n",
    "                (\n",
    "                    int(g.value(a, Aux.annotation_start)),\n",
    "                    int(g.value(a, Aux.annotation_end)),\n",
    "                    a\n",
    "                )\n",
    "                for a in g.objects(None, Aux.annotation)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph_analyzer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import collections\n",
    "\n",
    "@lru_cache()\n",
    "def morph_parses(word):\n",
    "    return morph_analyzer.parse(word.strip('.'))\n",
    "\n",
    "@lru_cache()\n",
    "def get_morpho(word):\n",
    "    parsed = morph_parses(word)\n",
    "    features = collections.defaultdict(lambda: 0)\n",
    "    for p in parsed:\n",
    "        for grammeme in p.tag.grammemes:\n",
    "            features[grammeme] += p.score\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lem</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36358.94</td>\n",
       "      <td>и</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27792.36</td>\n",
       "      <td>в</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20689.51</td>\n",
       "      <td>не</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18942.62</td>\n",
       "      <td>он</td>\n",
       "      <td>pron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16588.14</td>\n",
       "      <td>на</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score lem   pos\n",
       "i                    \n",
       "1  36358.94   и  misc\n",
       "2  27792.36   в  prep\n",
       "3  20689.51  не  misc\n",
       "4  18942.62  он  pron\n",
       "5  16588.14  на  prep"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "freq_dict = pd.read_csv('freq/5000lemma.utf8.num', sep=' ', names=['i','score','lem','pos'], index_col='i')\n",
    "freq_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordList:\n",
    "    def __init__(self, li, fmt):\n",
    "        self.set = set(li)\n",
    "        self.fmt = fmt\n",
    "        \n",
    "    def word_freq_score(self, word):\n",
    "        ret = collections.defaultdict(lambda: 0.0)\n",
    "        for p in morph_parses(word):\n",
    "            if p.normal_form in self.set:\n",
    "                ret[self.fmt.format(p.normal_form)] += p.score\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_word_list = WordList(freq_dict.lem, 'is_freq_{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_word_list = WordList(    \n",
    "    (\n",
    "        'ш шоссе ул улица пр пр-т проспект пр-д проезд наб набережная пл площадь линия'\n",
    "        ' п пос пгт п.г.т поселок дер деревня с село селение поселение ст станица г город селение х хутор'\n",
    "        ' д дом обл область р-н район столица округ р река'\n",
    "    ).split(),\n",
    "    'is_key_{}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhraseList:\n",
    "    def __init__(self, lines, fmt):\n",
    "        self.positions = collections.defaultdict(set)\n",
    "        for line in lines:\n",
    "            for i, tok in enumerate(tokenize(line)):\n",
    "                if tok['word']:\n",
    "                    self.positions[i].add(tok['word'])\n",
    "        self.positions = {\n",
    "            i: WordList(toks, fmt=(fmt + '_pos_{pos}').format(pos=i))\n",
    "            for i, toks in self.positions.items()\n",
    "        }\n",
    "    \n",
    "    def word_freq_score(self, word):\n",
    "        ret = {}\n",
    "        for wlist in self.positions.values():\n",
    "            ret.update(wlist.word_freq_score(word))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('osmmm/local.places.list') as places_file:\n",
    "    places_gazetteer = PhraseList(places_file, 'places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('osmmm/local.ways.list') as ways_file:\n",
    "    ways_gazetteer = PhraseList(ways_file, 'ways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194058"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_news = gensim.models.KeyedVectors.load_word2vec_format('w2v/news_0_300_2.bin', unicode_errors='ignore', binary=True)\n",
    "\n",
    "len(w2v_news.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class W2VAdder:\n",
    "    def __init__(self, w2v, fmt):\n",
    "        self.w2v = w2v\n",
    "        self.fmt = fmt\n",
    "    \n",
    "    def get_features(self, word):\n",
    "        ret = collections.defaultdict(lambda: 0.0)\n",
    "        for p in morph_parses(word):\n",
    "            k = '{}_{}'.format(p.normal_form, p.tag.POS)\n",
    "            if k in self.w2v:\n",
    "                ret.update({self.fmt.format(i): v*p.score for i, v in enumerate(self.w2v[k])})\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_news_adder = W2VAdder(w2v_news, 'w2v_{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_stream(paragraph, shift):\n",
    "    for token in tokenize(paragraph, shift):\n",
    "        token['word'] = token['word'].translate(str.maketrans('[]', '()', '<>%'))\n",
    "        if not token['word']:\n",
    "            continue\n",
    "            \n",
    "        token.update(get_morpho(token['word']))\n",
    "        \n",
    "        token['capitalized'] = token['word'][0].istitle()\n",
    "        token['isupper'] = token['word'][0].isupper()\n",
    "        token['islower'] = token['word'][0].islower()\n",
    "\n",
    "        if token.get('PNCT'):\n",
    "            token['punct_value'] = token['word']\n",
    "            \n",
    "        token['endswith_dot'] = token['word'].endswith('.')\n",
    "\n",
    "        yield token\n",
    "\n",
    "def raw_streams(text):\n",
    "    shift = 0\n",
    "    for paragraph in text.split(u\"\\u2028\\u2028\"):\n",
    "        yield raw_stream(paragraph, shift)\n",
    "        shift += len(paragraph) + len(u\"\\u2028\\u2028\")\n",
    "\n",
    "def add_annotations(token, annotator, g, manual_annotator):\n",
    "    annotation = annotator(token)\n",
    "    if annotation:\n",
    "        inst = g.value(annotation, Aux.instance)\n",
    "        token.update({\n",
    "            'ML_Type': str(g.value(inst, ML.Type)),\n",
    "#             'ML_GenericTerm': str(g.value(inst, ML.GenericTerm)),\n",
    "#             'ML_Name': str(g.value(inst, ML.Name)),\n",
    "        })\n",
    "        for li in [freq_word_list, key_word_list, places_gazetteer, ways_gazetteer]:\n",
    "            token.update(li.word_freq_score(token['word']))\n",
    "        token.update(w2v_news_adder.get_features(token['word']))\n",
    "    manu = manual_annotator(token)\n",
    "    if manu:\n",
    "        token['manual'] = manu\n",
    "    return token\n",
    "\n",
    "def annotated_stream(raw, annotator, g, man_ann):\n",
    "    for token in raw:\n",
    "        add_annotations(token, annotator, g, man_ann)\n",
    "        yield token\n",
    "        \n",
    "def parse_manual_annotations(text):\n",
    "    result = ''\n",
    "    res = []\n",
    "    for part in text.split('{{{'):\n",
    "        if '}}}' not in part:\n",
    "            result += part\n",
    "            continue\n",
    "            \n",
    "        clo = part.index('}}}')\n",
    "        ins, right = part[:clo], part[clo+len('}}}'):]\n",
    "        res.append((\n",
    "            len(result),\n",
    "            len(result) + len(ins),\n",
    "            'cool'\n",
    "        ))\n",
    "        result += ins + right\n",
    "    assert '{{{' not in result\n",
    "    assert '}}}' not in result\n",
    "    return res, result\n",
    "\n",
    "def annotated_streams(g):\n",
    "    annotator = RdfAnnotator(g)\n",
    "    texts = [o.value for o in g.objects(None, Aux.document_text)]\n",
    "    assert len(texts) == 1\n",
    "    text = texts[0]\n",
    "    manual, text = parse_manual_annotations(text)\n",
    "    for raw in raw_streams(text):\n",
    "        yield annotated_stream(raw, annotator, g, Annotator(manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_col(i, f):\n",
    "    return 'w{}_{}'.format(i, f)\n",
    "\n",
    "def windowize_cols(i, df):\n",
    "    return pandas.DataFrame(df, columns=[window_col(i, c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_reshape(df, window):\n",
    "    step = len(df)\n",
    "    values = df.values\n",
    "    \n",
    "    values = numpy.concatenate([\n",
    "        numpy.full((window, len(df.columns)), 0),\n",
    "        values,\n",
    "        numpy.full((window, len(df.columns)), 0),\n",
    "    ])\n",
    "\n",
    "    values = values.reshape(values.size,)\n",
    "    size = step * len(df.columns)\n",
    "    index = df.index\n",
    "\n",
    "    frame = pandas.DataFrame(index=index)\n",
    "#     for i, pos in enumerate(range(len(df.columns) * (window // 2), values.size - size + 1, len(df.columns))):\n",
    "    for i in range(window):\n",
    "        pos = (i + (window + 1) // 2) * len(df.columns)\n",
    "        cols = [window_col(i, x) for x in df.columns]\n",
    "        new_frame = pandas.DataFrame(\n",
    "            values[pos:pos+size].reshape((step, len(df.columns))),\n",
    "            index=index,\n",
    "            columns=cols,\n",
    "        )\n",
    "        frame = pandas.concat([frame, new_frame], axis=1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=90,\n",
       "       n_jobs=1, nthread=31, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.5)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3951"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(xgb1.feature_importances_ > 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.load('manual-data/Музей истории ГУЛАГа открылся в новом здании (nest_id = 77344277).xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [o.value for o in g.objects(None, Aux.document_text)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(57, 63, 'cool'),\n",
       "  (145, 168, 'cool'),\n",
       "  (216, 222, 'cool'),\n",
       "  (328, 351, 'cool'),\n",
       "  (645, 657, 'cool')],\n",
       " 'В пятницу, в День памяти жертв политических репрессий, в Москве открылся государственный музей истории ГУЛАГа, который переехал в новое здание в 1-м Самотечном переулке.\\u2028\\u2028Ранее сообщалось, что музей истории ГУЛАГа в Москве\\xa0 возобновит работу в пятницу, 30 октября, в День памяти жертв политических репрессий, в новом здании - в 1-м Самотечном переулке.\\u2028\\u2028Государственный музей истории ГУЛАГа был основан в 2001 году Антоном Владимировичем Антоновым-Овсеенко – известным историком, публицистом, общественным деятелем, в свое время прошедшим через сталинские лагеря как сын «врага народа». С 2004 по 2015 год Музей располагался в здании по адресу: ул. Петровка, д.16.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_manual_annotations(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdfa = RdfAnnotator(g)\n",
    "rdfa({'begin': 146, 'end': 147})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df, window):\n",
    "    drop_cols = [\n",
    "        col\n",
    "        for col in ['begin', 'end', 'word', 'ML_Type', 'Geox', 'manual']#, 'Abbr', 'Fixd', 'Sgtm']\n",
    "        if col in df.columns\n",
    "    ]\n",
    "    return rolling_reshape(df.drop(drop_cols, axis=1), window)\n",
    "\n",
    "def make_target(df, window):\n",
    "    if 'ML_Type' in df.columns:\n",
    "        return df['ML_Type'].fillna('')\n",
    "    else:\n",
    "        return numpy.asarray([''] * len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_annotated_streams(pattern):\n",
    "    datasets = glob.glob(pattern)\n",
    "    for ds in datasets:\n",
    "        g = rdflib.Graph()\n",
    "        g.load(ds)\n",
    "        yield from annotated_streams(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def read_datasets(pattern, texts_number):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    heres = []\n",
    "    sz = 0\n",
    "    for i, astr in enumerate(itertools.islice(all_annotated_streams(pattern), texts_number)):\n",
    "        entries = list(astr)\n",
    "        here = pandas.DataFrame(\n",
    "            entries,\n",
    "            index=np.arange(sz, sz + len(entries))\n",
    "        )\n",
    "        heres.append(here)\n",
    "        Xs.append(make_features(here, WINDOW_SIZE))\n",
    "        Ys.append(make_target(here, WINDOW_SIZE))\n",
    "        sz += len(entries)\n",
    "        print('\\r{:5}/{} {}'.format(i+1, texts_number, sz), end='')\n",
    "        assert len(Xs[-1]) == len(Ys[-1])\n",
    "    print()\n",
    "    \n",
    "    tokens = pandas.concat(heres)\n",
    "    del heres\n",
    "    \n",
    "    X = pandas.concat(Xs)\n",
    "    del Xs\n",
    "    print('X concated')\n",
    "    \n",
    "    X = pandas.get_dummies(X, columns=[window_col(i, 'punct_value') for i in range(WINDOW_SIZE)])\n",
    "    X.fillna(0.0, inplace=True)\n",
    "    print('X fillnad')\n",
    "    \n",
    "    cap = [\n",
    "        window_col(i, bool_feat)\n",
    "        for i in range(WINDOW_SIZE)\n",
    "        for bool_feat in tokens.columns[tokens.dtypes == np.dtype('bool')]\n",
    "    ]\n",
    "    X[cap] = X[cap].astype(bool)\n",
    "    print('X astyped')\n",
    "    \n",
    "    Y = numpy.concatenate(Ys)\n",
    "    del Ys\n",
    "    print('Y concated')\n",
    "\n",
    "    Y = Y.astype(bool)\n",
    "    print('Y astyped')\n",
    "    \n",
    "    return tokens, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6911/None 398071\n",
      "X concated\n",
      "X fillnad\n",
      "X astyped\n",
      "Y concated\n",
      "Y astyped\n",
      "CPU times: user 22min 25s, sys: 59.9 s, total: 23min 25s\n",
      "Wall time: 23min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens, X, Y = read_datasets('data/*.xml', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398071, 3951)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  807/None 41335\n",
      "X concated\n",
      "X fillnad\n",
      "X astyped\n",
      "Y concated\n",
      "Y astyped\n"
     ]
    }
   ],
   "source": [
    "man_tokens, man_X, man_Y_abbyy = read_datasets('manual-data/*.xml', None)\n",
    "man_Y_man = (man_tokens.manual == 'cool')\n",
    "man_tokens = man_tokens.reindex(columns=tokens.columns)\n",
    "man_X = man_X.reindex(columns=X.columns).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398071"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41335"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(man_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare = join_outputs(dropouts['>.<'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.85      0.73      0.79      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(man_Y_man, man_Y_abbyy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41335"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare[compare.out != compare.abbyy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38243,   345],\n",
       "       [  736,  2011]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(compare.man, compare.abbyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 0, 'end': 9, 'word': 'Волгоград'},\n",
       " {'begin': 9, 'end': 10, 'word': ','},\n",
       " {'begin': 11, 'end': 13, 'word': 'ул'},\n",
       " {'begin': 15, 'end': 25, 'word': 'Грановитая'}]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenize('Волгоград, ул. Грановитая'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_outputs(out):\n",
    "    compare = rolling_reshape(man_tokens[['word']], 7)\n",
    "    compare['man'] = man_Y_man\n",
    "    compare['abbyy'] = man_Y_abbyy\n",
    "    compare['out'] = out\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def drop_by_re(df, r, invert):\n",
    "    return df.drop([c for c in df.columns if bool(re.search(r, c)) != invert], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dropped(drop_re, alg_src, invert):\n",
    "    xre = drop_by_re(X, drop_re, invert)\n",
    "    manx = drop_by_re(man_X, drop_re, invert)\n",
    "    \n",
    "    alg = XGBClassifier(**alg_src.get_params())\n",
    "    alg.fit(xre, Y)\n",
    "    return alg, alg.predict(manx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def eval_out(out):\n",
    "    print('man:' + classification_report(man_Y_man, out))\n",
    "    print('abbyy:' + classification_report(man_Y_abbyy, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_dropped(drop_re, alg_src, invert=False):\n",
    "    alg, out = run_dropped(drop_re, alg_src, invert)\n",
    "    eval_out(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_res = ['_ways_', '_places_', '_w2v_', 'is_freq', 'is_key_', 'capitalized|islower|isupper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropouts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capitalized|islower|isupper|is_freq\n",
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.87      0.72      0.79      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00     38979\n",
      "       True       0.96      0.92      0.94      2356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     41335\n",
      "\n",
      "capitalized|islower|isupper|is_key_\n",
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.87      0.72      0.79      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00     38979\n",
      "       True       0.96      0.93      0.94      2356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     41335\n",
      "\n",
      "CPU times: user 2h 43min 29s, sys: 1min 49s, total: 2h 45min 18s\n",
      "Wall time: 11min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    for drops in itertools.combinations(feature_res, i):\n",
    "        k = '|'.join(sorted(drops)) or '>.<'\n",
    "        if k not in dropouts:\n",
    "            print(k)\n",
    "            dropouts[k] = eval_dropped(k, xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.85      0.72      0.78      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.99      0.99     38979\n",
      "       True       0.91      0.90      0.90      2356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts['not w2v,places,ways']= eval_dropped('_places_|_w2v_|_ways', xgb1, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      1.00      0.98     38588\n",
      "       True       0.95      0.40      0.56      2747\n",
      "\n",
      "avg / total       0.96      0.96      0.95     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.99      0.98     38979\n",
      "       True       0.71      0.35      0.47      2356\n",
      "\n",
      "avg / total       0.95      0.95      0.95     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts['morpho_only'] = eval_dropped(\n",
    "    'places|w2v|ways|freq|is_key|capital|lower|upper|punct_value',\n",
    "    xgb1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.87      0.74      0.80      2747\n",
      "\n",
      "avg / total       0.97      0.98      0.97     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00     38979\n",
      "       True       0.94      0.93      0.93      2356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts['but_morpho'] = eval_dropped(\n",
    "    'places|w2v|ways|freq|is_key|capital|lower|upper|punct_value',\n",
    "    xgb1,\n",
    "    invert=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      0.99      0.98     38588\n",
      "       True       0.81      0.60      0.69      2747\n",
      "\n",
      "avg / total       0.96      0.96      0.96     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38979\n",
      "       True       0.82      0.70      0.75      2356\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts['gaz'] = eval_dropped('places|ways', xgb1, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      1.00      0.99     38588\n",
      "       True       0.93      0.63      0.75      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n",
      "abbyy:             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      0.99     38979\n",
      "       True       0.98      0.78      0.87      2356\n",
      "\n",
      "avg / total       0.99      0.99      0.99     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts['w2v_only'] = eval_dropped('w2v', xgb1, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'>.<': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|_w2v_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|_w2v_|_ways_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|_ways_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|capitalized|islower|isupper': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|is_freq': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_places_|is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_w2v_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_w2v_|_ways_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_w2v_|capitalized|islower|isupper': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_w2v_|is_freq': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_w2v_|is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_ways_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_ways_|capitalized|islower|isupper': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_ways_|is_freq': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " '_ways_|is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'but_morpho': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'capitalized|islower|isupper': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'capitalized|islower|isupper|is_freq': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'capitalized|islower|isupper|is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'gaz': array([False, False, False, ..., False, False, False], dtype=bool),\n",
       " 'is_freq': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'is_freq|is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'is_key_': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'morpho': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'morpho_only': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'not w2v,places,ways': array([False,  True, False, ..., False, False, False], dtype=bool),\n",
       " 'w2v_only': array([False,  True, False, ..., False, False, False], dtype=bool)}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsets = [\n",
    "    '>.<',\n",
    "    'but_morpho',\n",
    "    'capitalized|islower|isupper',\n",
    "    'is_freq|is_key_',\n",
    "    '_places_|_ways_',\n",
    "    '_w2v_',\n",
    "    'morpho_only',\n",
    "    'gaz',\n",
    "    '_w2v_|capitalized|islower|isupper',\n",
    "    '_places_|_w2v_|_ways_',\n",
    "    'not w2v,places,ways',\n",
    "    'w2v_only',\n",
    "]\n",
    "\n",
    "dropcomp = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'pred': pred,\n",
    "\n",
    "            'precision': metrics.precision_score(man_Y_man, pred),\n",
    "            'recall': metrics.recall_score(man_Y_man, pred),\n",
    "            'f1': metrics.f1_score(man_Y_man, pred),\n",
    "            \n",
    "#             'a_precision': metrics.precision_score(man_Y_abbyy, pred),\n",
    "#             'a_recall': metrics.recall_score(man_Y_abbyy, pred),\n",
    "#             'a_f1': metrics.f1_score(man_Y_abbyy, pred),\n",
    "        } \n",
    "        for k, pred in [(kk, dropouts[kk]) for kk in fsets]\n",
    "    ],\n",
    "    index=['F{}'.format(i) for i in range(1, len(fsets) + 1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = dropcomp.drop(['pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38303,   285],\n",
       "       [  755,  1992]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(compare.man, compare.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38243,   345],\n",
       "       [  736,  2011]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(compare.man, compare.abbyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &   F1 &   F2 &   F3 &   F4 &   F5 &   F6 &   F7 &   F8 &   F9 &  F10 &  F11 &  F12 \\\\\n",
      "\\midrule\n",
      "f1        & 0.79 &  0.8 & 0.79 & 0.79 & 0.79 & 0.78 & 0.56 & 0.69 & 0.76 & 0.71 & 0.78 & 0.75 \\\\\n",
      "precision & 0.87 & 0.87 & 0.87 & 0.88 & 0.93 & 0.88 & 0.95 & 0.81 & 0.87 & 0.97 & 0.85 & 0.93 \\\\\n",
      "recall    & 0.73 & 0.74 & 0.72 & 0.73 & 0.68 & 0.71 &  0.4 &  0.6 & 0.68 & 0.57 & 0.72 & 0.63 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dropcomp.drop(['pred'], axis=1).transpose().to_latex(\n",
    "    float_format=lambda f: str(round(f,2))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = pd.Series(xgb1.feature_importances_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-382-210afd3dcbb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'importances' is not defined"
     ]
    }
   ],
   "source": [
    "importances.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduced(x, number):\n",
    "    return x[importances.sort_values(ascending=False).head(number).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XGBoost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/lib64/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_xgb(alg, dtrain, ytrain, dtest, ytest, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain.values, label=ytrain)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, stratified=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, ytrain, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytrain, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytrain, dtrain_predprob))\n",
    "    \n",
    "#     Predict on testing data:\n",
    "    results = alg.predict_proba(dtest)[:,1]\n",
    "    print('AUC Score (Test): %f' % metrics.roc_auc_score(ytest, results))\n",
    "\n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False).head(100)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=90,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.5,\n",
    "    objective='binary:logistic',\n",
    "    nthread=31,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_xgb(xgb1, X, Y, man_X, man_Y_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=322,\n",
       "       n_jobs=1, nthread=30, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup = pd.HDFStore('backup.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, tokens = backup.X, backup.Y, backup.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot properly create the storer for: [_TYPE_MAP] [group->/Y (Group) '',value-><class 'numpy.ndarray'>,format->fixed,append->False,kwargs->{'encoding': None}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_create_storer\u001b[0;34m(self, group, format, value, append, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m                     \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TYPE_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'numpy.ndarray'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-e3faada3466b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, key, value, format, append, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"io.hdf.default_format\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'fixed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_to_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[0;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         s = self._create_storer(group, format, value, append=append,\n\u001b[0;32m-> 1313\u001b[0;31m                                 encoding=encoding, **kwargs)\n\u001b[0m\u001b[1;32m   1314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;31m# raise if we are trying to append to a Fixed format,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_create_storer\u001b[0;34m(self, group, format, value, append, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                     \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TYPE_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_TYPE_MAP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;31m# we are actually a table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                 \u001b[0;34m\"cannot properly create the storer for: [%s] [group->%s,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;34m\"value->%s,format->%s,append->%s,kwargs->%s]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m             )\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot properly create the storer for: [_TYPE_MAP] [group->/Y (Group) '',value-><class 'numpy.ndarray'>,format->fixed,append->False,kwargs->{'encoding': None}]"
     ]
    }
   ],
   "source": [
    "backup['X'], backup['Y'], backup['tokens'] = X, Y, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite as crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crf = crfsuite.CRF(c1=0.1, c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = [\n",
    "    window_col(i, bool_feat)\n",
    "    for i in range(WINDOW_SIZE)\n",
    "    for bool_feat in tokens.columns[tokens.dtypes == np.dtype('bool')]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[cap] = X[cap].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(X.head(1000).values)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.76 s, sys: 5.68 s, total: 12.4 s\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm=None, all_possible_states=None, all_possible_transitions=None,\n",
       "  averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "  calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=None,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf.fit([X.values], [[str(y) for y in Y]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['False', 'True']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y = [s == 'True' for ss in crf.predict(man_X.head(1000).values) for s in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3941000"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ro = X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('bool'), dtype('uint8')], dtype=object)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(c.dtype for c in ro).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(X.head(1000).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_rfc_input(pat, num):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    manys = []\n",
    "    for entries in itertools.islice(all_annotated_streams(pat), num):\n",
    "        Xs.append([])\n",
    "        Ys.append([])\n",
    "        manys.append([])\n",
    "        for e in entries:\n",
    "            Xs[-1].append({\n",
    "                k: v for k, v in e.items()\n",
    "                if k not in {'ML_Type', 'manual', 'begin', 'end', 'Geox'} and '_w2v_' not in k\n",
    "            })\n",
    "            pa = morph_parses(e['word'])\n",
    "            if pa:\n",
    "                Xs[-1][-1]['lem'] = pa[0].normal_form\n",
    "            Ys[-1].append(e.get('ML_Type', 'no'))\n",
    "            manys[-1].append(e.get('manual', 'no'))\n",
    "    return Xs, Ys, manys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 207 ms, total: 1min 55s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Xs, Ys, _ = read_rfc_input('data/*.xml', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 33s, sys: 1.02 ms, total: 4min 33s\n",
      "Wall time: 4min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm=None, all_possible_states=None, all_possible_transitions=None,\n",
       "  averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "  calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=None,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf.fit(Xs, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 40.2 ms, total: 12.9 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "manxs, manabbyys, manys = read_rfc_input('manual-data/*.xml', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 2.02 ms, total: 422 ms\n",
      "Wall time: 423 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "manpreds = crf.predict(manxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manysflat = [m != 'no' for m in itertools.chain(*manys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manpredsflat = [m != 'no' for m in itertools.chain(*manpreds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.99      0.99     38588\n",
      "       True       0.87      0.72      0.79      2747\n",
      "\n",
      "avg / total       0.97      0.97      0.97     41335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(manysflat, manpredsflat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PREP',\n",
       " 'endswith_dot',\n",
       " 'islower',\n",
       " 'capitalized',\n",
       " 'Vpre',\n",
       " 'isupper',\n",
       " 'lem:в',\n",
       " 'nomn',\n",
       " 'masc',\n",
       " 'accs',\n",
       " 'sing',\n",
       " 'NOUN',\n",
       " 'inan',\n",
       " 'Abbr',\n",
       " 'Fixd',\n",
       " 'word:в',\n",
       " 'plur',\n",
       " 'loct',\n",
       " 'ablt',\n",
       " 'datv',\n",
       " 'gent',\n",
       " 'lem:офис',\n",
       " 'femn',\n",
       " 'ADJF',\n",
       " 'lem:социальный',\n",
       " 'Qual',\n",
       " 'loc2',\n",
       " 'lem:сеть',\n",
       " 'lem:\"',\n",
       " 'word:\"',\n",
       " 'PNCT',\n",
       " 'punct_value:\"',\n",
       " 'Sgtm',\n",
       " 'lem:вконтакте',\n",
       " 'lem:дом',\n",
       " 'Surn',\n",
       " 'anim',\n",
       " 'PRCL',\n",
       " 'INTJ',\n",
       " 'lem:на',\n",
       " 'w2v_88',\n",
       " 'w2v_288',\n",
       " 'w2v_293',\n",
       " 'w2v_37',\n",
       " 'w2v_260',\n",
       " 'w2v_268',\n",
       " 'w2v_291',\n",
       " 'w2v_48',\n",
       " 'w2v_26',\n",
       " 'w2v_1',\n",
       " 'w2v_170',\n",
       " 'w2v_52',\n",
       " 'w2v_86',\n",
       " 'w2v_213',\n",
       " 'w2v_97',\n",
       " 'w2v_29',\n",
       " 'w2v_136',\n",
       " 'w2v_276',\n",
       " 'w2v_69',\n",
       " 'w2v_248',\n",
       " 'w2v_258',\n",
       " 'w2v_215',\n",
       " 'w2v_296',\n",
       " 'w2v_39',\n",
       " 'w2v_221',\n",
       " 'w2v_216',\n",
       " 'w2v_149',\n",
       " 'w2v_189',\n",
       " 'w2v_102',\n",
       " 'w2v_5',\n",
       " 'w2v_63',\n",
       " 'w2v_46',\n",
       " 'w2v_236',\n",
       " 'w2v_204',\n",
       " 'w2v_141',\n",
       " 'w2v_65',\n",
       " 'w2v_4',\n",
       " 'w2v_148',\n",
       " 'w2v_145',\n",
       " 'w2v_90',\n",
       " 'w2v_19',\n",
       " 'w2v_197',\n",
       " 'w2v_75',\n",
       " 'w2v_40',\n",
       " 'w2v_251',\n",
       " 'w2v_180',\n",
       " 'w2v_68',\n",
       " 'w2v_24',\n",
       " 'w2v_274',\n",
       " 'w2v_169',\n",
       " 'w2v_172',\n",
       " 'w2v_35',\n",
       " 'w2v_243',\n",
       " 'w2v_85',\n",
       " 'w2v_286',\n",
       " 'w2v_74',\n",
       " 'w2v_111',\n",
       " 'w2v_202',\n",
       " 'w2v_16',\n",
       " 'w2v_43',\n",
       " 'w2v_110',\n",
       " 'w2v_158',\n",
       " 'w2v_112',\n",
       " 'w2v_186',\n",
       " 'w2v_146',\n",
       " 'w2v_0',\n",
       " 'w2v_129',\n",
       " 'w2v_18',\n",
       " 'w2v_126',\n",
       " 'w2v_196',\n",
       " 'w2v_233',\n",
       " 'w2v_105',\n",
       " 'w2v_91',\n",
       " 'w2v_151',\n",
       " 'w2v_249',\n",
       " 'w2v_8',\n",
       " 'w2v_163',\n",
       " 'w2v_181',\n",
       " 'w2v_82',\n",
       " 'w2v_224',\n",
       " 'w2v_59',\n",
       " 'w2v_281',\n",
       " 'w2v_155',\n",
       " 'w2v_182',\n",
       " 'w2v_242',\n",
       " 'w2v_144',\n",
       " 'w2v_238',\n",
       " 'w2v_36',\n",
       " 'w2v_96',\n",
       " 'w2v_10',\n",
       " 'w2v_231',\n",
       " 'w2v_100',\n",
       " 'w2v_94',\n",
       " 'w2v_187',\n",
       " 'w2v_77',\n",
       " 'w2v_134',\n",
       " 'w2v_147',\n",
       " 'lem:невский',\n",
       " 'w2v_214',\n",
       " 'w2v_118',\n",
       " 'w2v_124',\n",
       " 'w2v_299',\n",
       " 'w2v_184',\n",
       " 'w2v_115',\n",
       " 'w2v_76',\n",
       " 'w2v_209',\n",
       " 'w2v_93',\n",
       " 'w2v_292',\n",
       " 'w2v_71',\n",
       " 'w2v_277',\n",
       " 'w2v_237',\n",
       " 'w2v_84',\n",
       " 'w2v_185',\n",
       " 'w2v_250',\n",
       " 'w2v_254',\n",
       " 'w2v_101',\n",
       " 'w2v_21',\n",
       " 'w2v_109',\n",
       " 'w2v_225',\n",
       " 'w2v_244',\n",
       " 'neut',\n",
       " 'w2v_92',\n",
       " 'w2v_70',\n",
       " 'w2v_72',\n",
       " 'w2v_67',\n",
       " 'w2v_279',\n",
       " 'w2v_278',\n",
       " 'w2v_285',\n",
       " 'w2v_98',\n",
       " 'w2v_201',\n",
       " 'w2v_164',\n",
       " 'w2v_226',\n",
       " 'w2v_12',\n",
       " 'w2v_28',\n",
       " 'w2v_38',\n",
       " 'w2v_195',\n",
       " 'w2v_47',\n",
       " 'w2v_27',\n",
       " 'w2v_30',\n",
       " 'w2v_3',\n",
       " 'w2v_269',\n",
       " 'word:Невском',\n",
       " 'w2v_297',\n",
       " 'w2v_289',\n",
       " 'w2v_20',\n",
       " 'w2v_287',\n",
       " 'w2v_139',\n",
       " 'w2v_168',\n",
       " 'w2v_284',\n",
       " 'w2v_135',\n",
       " 'w2v_61',\n",
       " 'w2v_219',\n",
       " 'w2v_207',\n",
       " 'w2v_298',\n",
       " 'w2v_194',\n",
       " 'w2v_106',\n",
       " 'w2v_203',\n",
       " 'w2v_89',\n",
       " 'w2v_227',\n",
       " 'w2v_241',\n",
       " 'w2v_252',\n",
       " 'w2v_7',\n",
       " 'w2v_218',\n",
       " 'w2v_229',\n",
       " 'w2v_263',\n",
       " 'w2v_62',\n",
       " 'w2v_167',\n",
       " 'w2v_32',\n",
       " 'w2v_15',\n",
       " 'w2v_174',\n",
       " 'w2v_119',\n",
       " 'w2v_211',\n",
       " 'w2v_143',\n",
       " 'w2v_137',\n",
       " 'w2v_133',\n",
       " 'w2v_290',\n",
       " 'w2v_23',\n",
       " 'w2v_113',\n",
       " 'w2v_34',\n",
       " 'w2v_64',\n",
       " 'w2v_41',\n",
       " 'w2v_122',\n",
       " 'w2v_66',\n",
       " 'w2v_55',\n",
       " 'w2v_166',\n",
       " 'w2v_116',\n",
       " 'w2v_177',\n",
       " 'w2v_140',\n",
       " 'w2v_271',\n",
       " 'w2v_247',\n",
       " 'w2v_257',\n",
       " 'w2v_208',\n",
       " 'w2v_103',\n",
       " 'w2v_159',\n",
       " 'w2v_49',\n",
       " 'w2v_199',\n",
       " 'w2v_220',\n",
       " 'w2v_217',\n",
       " 'w2v_267',\n",
       " 'w2v_153',\n",
       " 'w2v_222',\n",
       " 'w2v_261',\n",
       " 'w2v_80',\n",
       " 'w2v_264',\n",
       " 'w2v_176',\n",
       " 'w2v_270',\n",
       " 'w2v_265',\n",
       " 'w2v_107',\n",
       " 'w2v_6',\n",
       " 'w2v_234',\n",
       " 'w2v_240',\n",
       " 'w2v_99',\n",
       " 'w2v_50',\n",
       " 'w2v_171',\n",
       " 'w2v_53',\n",
       " 'w2v_230',\n",
       " 'w2v_178',\n",
       " 'w2v_275',\n",
       " 'w2v_57',\n",
       " 'w2v_282',\n",
       " 'w2v_31',\n",
       " 'w2v_114',\n",
       " 'w2v_14',\n",
       " 'w2v_9',\n",
       " 'w2v_161',\n",
       " 'w2v_200',\n",
       " 'ways_pos_5',\n",
       " 'ways_pos_3',\n",
       " 'ways_pos_2',\n",
       " 'is_key_проспект',\n",
       " 'ways_pos_1',\n",
       " 'ways_pos_0',\n",
       " 'lem:проспект',\n",
       " 'is_freq_проспект',\n",
       " 'word:проспекте',\n",
       " 'ways_pos_4',\n",
       " 'lem:,',\n",
       " 'word:,',\n",
       " 'punct_value:,',\n",
       " 'CONJ',\n",
       " 'lem:а',\n",
       " 'lem:также',\n",
       " 'lem:квартира',\n",
       " 'word:Дурова',\n",
       " 'lem:дуров',\n",
       " 'lem:петербург',\n",
       " 'is_freq_петербург',\n",
       " 'intr',\n",
       " 'VERB',\n",
       " 'indc',\n",
       " 'past',\n",
       " 'impf',\n",
       " 'lem:быть',\n",
       " 'pssv',\n",
       " 'perf',\n",
       " 'lem:провести',\n",
       " 'PRTS',\n",
       " 'word:А',\n",
       " 'Patr',\n",
       " 'Name',\n",
       " 'Init',\n",
       " 'lem:интернет',\n",
       " 'Subx',\n",
       " 'lem:который',\n",
       " 'Apro',\n",
       " 'Anph',\n",
       " 'lem:павел',\n",
       " 'Prnt',\n",
       " 'lem:поздний',\n",
       " 'COMP',\n",
       " 'lem:сми',\n",
       " 'word:СМИ',\n",
       " 'Pltm',\n",
       " 'GNdr',\n",
       " 'tran',\n",
       " 'NPRO',\n",
       " '3per',\n",
       " 'lem:он',\n",
       " 'lem:липовый',\n",
       " 'lem:авария',\n",
       " 'word:улице',\n",
       " 'lem:улица',\n",
       " 'lem:москва',\n",
       " 'is_freq_москва',\n",
       " 'word:Москве',\n",
       " 'word:Алексей',\n",
       " 'lem:алексей',\n",
       " 'lem:серов',\n",
       " 'lem:новое',\n",
       " 'lem:группа',\n",
       " 'word:По',\n",
       " 'lem:по',\n",
       " 'lem:скорость',\n",
       " 'lem:движение',\n",
       " 'INFN',\n",
       " 'word:до',\n",
       " 'lem:до',\n",
       " 'ADVB',\n",
       " 'word:не',\n",
       " 'lem:не',\n",
       " 'lem:пункт',\n",
       " 'NUMR',\n",
       " 'lem:километр',\n",
       " 'word:На',\n",
       " 'lem:предприятие',\n",
       " 'GRND',\n",
       " 'ADJS',\n",
       " 'Ms-f',\n",
       " 'Poss',\n",
       " 'lem:деревянный',\n",
       " 'word:Площадь',\n",
       " 'lem:площадь',\n",
       " 'lem:пожар',\n",
       " 'intg',\n",
       " 'NUMB',\n",
       " 'lem:метр',\n",
       " 'word:Огонь',\n",
       " 'lem:огонь',\n",
       " 'word:и',\n",
       " 'lem:и',\n",
       " 'lem:о',\n",
       " 'lem:это',\n",
       " 'word:МЧС',\n",
       " 'lem:мчс',\n",
       " 'Orgn',\n",
       " 'word:Виталий',\n",
       " 'lem:виталий',\n",
       " 'lem::',\n",
       " 'word::',\n",
       " 'punct_value::',\n",
       " 'ways_pos_7',\n",
       " 'ways_pos_6',\n",
       " 'ways_pos_10',\n",
       " 'is_key_улица',\n",
       " 'places_pos_0',\n",
       " 'ways_pos_13',\n",
       " 'is_freq_улица',\n",
       " 'lem:социалистический',\n",
       " 'is_freq_социалистический',\n",
       " 'lem:возгорание',\n",
       " 'PRTF',\n",
       " 'actv',\n",
       " 'pres',\n",
       " 'lem:нет',\n",
       " 'PRED',\n",
       " 'word:В',\n",
       " 'lem:с',\n",
       " 'lem:проведение',\n",
       " 'word:12',\n",
       " 'lem:12',\n",
       " 'word:мая',\n",
       " 'lem:май',\n",
       " 'lem:массовый',\n",
       " 'lem:мероприятие',\n",
       " 'futr',\n",
       " 'lem:транспорт',\n",
       " 'lem:число',\n",
       " 'lem:общественный',\n",
       " 'lem:столичный',\n",
       " 'lem:департамент',\n",
       " 'word:Как',\n",
       " 'lem:как',\n",
       " 'lem:корреспондент',\n",
       " 'word:ИА',\n",
       " 'UNKN',\n",
       " 'lem:иа',\n",
       " 'word:REGNUM',\n",
       " 'LATN',\n",
       " 'lem:regnum',\n",
       " 'lem:пресс-служба',\n",
       " 'lem:военный',\n",
       " 'lem:парад',\n",
       " 'word:Победы',\n",
       " 'lem:победа',\n",
       " 'lem:красный',\n",
       " 'is_freq_красный',\n",
       " 'word:Красной',\n",
       " 'places_pos_1',\n",
       " 'is_freq_площадь',\n",
       " 'word:площади',\n",
       " 'is_key_площадь',\n",
       " 'word:00',\n",
       " 'lem:00',\n",
       " 'word:по',\n",
       " '1per',\n",
       " 'word:Ленинградскому',\n",
       " 'lem:ленинградский',\n",
       " 'is_freq_ленинградский',\n",
       " 'places_pos_2',\n",
       " 'word:1-я',\n",
       " 'ways_pos_8',\n",
       " 'places_pos_3',\n",
       " 'ways_pos_11',\n",
       " 'lem:1-я',\n",
       " 'word:Тверская-Ямская',\n",
       " 'lem:тверская-ямская',\n",
       " 'lem:тверская',\n",
       " 'word:Тверская',\n",
       " 'lem:воздвиженка',\n",
       " 'word:Воздвиженка',\n",
       " 'word:Новый',\n",
       " 'is_freq_новый',\n",
       " 'lem:новый',\n",
       " 'lem:арбат',\n",
       " 'word:Арбат',\n",
       " 'word:Кремлевской',\n",
       " 'lem:кремлёвский',\n",
       " 'lem:набережная',\n",
       " 'is_key_набережная',\n",
       " 'is_freq_набережная',\n",
       " 'word:набережной',\n",
       " 'word:Садовому',\n",
       " 'lem:садовый',\n",
       " 'lem:кольцо',\n",
       " 'is_freq_кольцо',\n",
       " 'lem:участок',\n",
       " 'word:от',\n",
       " 'lem:от',\n",
       " 'word:Смоленской',\n",
       " 'lem:смоленский',\n",
       " 'word:Садовая-Каретная',\n",
       " 'lem:садовый-каретный',\n",
       " 'lem:центральный',\n",
       " 'excl',\n",
       " 'impr',\n",
       " 'lem:часть',\n",
       " 'word:города',\n",
       " 'lem:город',\n",
       " 'word:Также',\n",
       " 'lem:международный',\n",
       " 'word:16',\n",
       " 'lem:16',\n",
       " 'lem:праздник',\n",
       " 'word:Красная',\n",
       " 'lem:этот',\n",
       " 'lem:день',\n",
       " 'lem:(',\n",
       " 'word:(',\n",
       " 'punct_value:(',\n",
       " 'lem:)',\n",
       " 'word:)',\n",
       " 'punct_value:)',\n",
       " 'word:ЦАО',\n",
       " 'lem:цао',\n",
       " 'lem:-',\n",
       " 'word:-',\n",
       " 'punct_value:-',\n",
       " 'lem:сергей',\n",
       " 'word:Сергея',\n",
       " 'lem:макеев',\n",
       " 'word:Макеева',\n",
       " 'Infr',\n",
       " 'word:года',\n",
       " 'lem:год',\n",
       " 'word:Звенигородского',\n",
       " 'is_freq_шоссе',\n",
       " 'is_key_шоссе',\n",
       " 'lem:шоссе',\n",
       " 'word:шоссе',\n",
       " 'word:Большой',\n",
       " 'is_freq_большой',\n",
       " 'lem:большой',\n",
       " 'word:объезд',\n",
       " 'lem:объезд',\n",
       " 'word:Звенигородскому',\n",
       " 'lem:фестивальный',\n",
       " 'lem:лавочкин',\n",
       " 'word:Лавочкина',\n",
       " 'word:ЮВАО',\n",
       " 'lem:ювао',\n",
       " 'is_freq_академик',\n",
       " 'lem:академик',\n",
       " 'word:Академика',\n",
       " 'lem:волгоградский',\n",
       " 'word:Волгоградского',\n",
       " 'word:1-й',\n",
       " 'lem:1-й',\n",
       " 'word:Объезд',\n",
       " 'lem:рязанский',\n",
       " 'word:ЗАО',\n",
       " 'lem:зао',\n",
       " 'word:стороны',\n",
       " 'lem:сторона',\n",
       " 'lem:мкад',\n",
       " 'word:МКАД',\n",
       " 'lem:озёрный',\n",
       " 'word:Рябиновая',\n",
       " 'lem:рябиновый',\n",
       " 'lem:к',\n",
       " 'lem:кладбище',\n",
       " 'lem:калужский',\n",
       " 'word:Калужского',\n",
       " 'lem:киевский',\n",
       " 'word:Киевского',\n",
       " 'word:Одновременно',\n",
       " 'lem:одновременно',\n",
       " 'lem:автомобиль',\n",
       " 'lem:славянский',\n",
       " 'lem:варварка',\n",
       " 'lem:ильинка',\n",
       " 'word:Ильинка',\n",
       " 'word:Москворецкому',\n",
       " 'lem:москворецкий',\n",
       " 'lem:мост',\n",
       " 'lem:сообщение',\n",
       " 'lem:сайт',\n",
       " 'lem:управление',\n",
       " 'word:Управления',\n",
       " 'word:ГИБДД',\n",
       " 'lem:гибдд',\n",
       " 'word:ГУ',\n",
       " 'lem:гу',\n",
       " 'word:МВД',\n",
       " 'lem:мвд',\n",
       " 'word:РФ',\n",
       " 'lem:рф',\n",
       " 'lem:акция',\n",
       " 'lem:шествие',\n",
       " 'word:Якиманке',\n",
       " 'lem:якиманка',\n",
       " 'lem:митинг',\n",
       " 'word:Болотной',\n",
       " 'lem:болотный',\n",
       " 'word:Пушкинской',\n",
       " 'lem:пушкинский',\n",
       " 'word:Поклонной',\n",
       " 'lem:поклонный',\n",
       " 'lem:сахаров',\n",
       " 'word:Сахарова',\n",
       " 'lem:организатор',\n",
       " 'lem:глава',\n",
       " 'lem:константин',\n",
       " 'lem:боровой',\n",
       " 'lem:центр',\n",
       " 'lem:организация',\n",
       " 'is_freq_мир',\n",
       " 'lem:мир',\n",
       " 'word:Мира',\n",
       " 'lem:система',\n",
       " 'lem:такой',\n",
       " 'lem:рубль',\n",
       " 'word:Пока',\n",
       " 'lem:пока',\n",
       " 'lem:один',\n",
       " 'lem:конец',\n",
       " 'lem:последний',\n",
       " 'lem:мэрия',\n",
       " 'lem:борьба',\n",
       " 'lem:пробка',\n",
       " 'lem:специальный',\n",
       " 'word:можно',\n",
       " 'lem:можно',\n",
       " 'lem:направление',\n",
       " 'lem:время',\n",
       " 'word:Сегодня',\n",
       " 'lem:сегодня',\n",
       " 'lem:шереметьевский',\n",
       " 'word:Волгоградском',\n",
       " 'word:Ярославском',\n",
       " 'lem:ярославский',\n",
       " 'lem:—',\n",
       " 'word:—',\n",
       " 'punct_value:—',\n",
       " 'word:6',\n",
       " 'lem:6',\n",
       " 'word:сторону',\n",
       " 'lem:22',\n",
       " 'word:области',\n",
       " 'lem:область',\n",
       " 'word:году',\n",
       " 'word:ДТП',\n",
       " 'lem:дтп',\n",
       " 'word:Новые',\n",
       " 'lem:два',\n",
       " 'lem:весь',\n",
       " 'word:время',\n",
       " 'lem:уведомление',\n",
       " 'word:Глава',\n",
       " 'word:Вадим',\n",
       " 'lem:вадим',\n",
       " 'lem:водитель',\n",
       " 'lem:информация',\n",
       " 'word:результате',\n",
       " 'lem:результат',\n",
       " 'lem:стихийный',\n",
       " 'word:Крымском',\n",
       " 'lem:крымский',\n",
       " 'word:районе',\n",
       " 'lem:район',\n",
       " 'lem:краснодарский',\n",
       " 'word:Краснодарского',\n",
       " 'lem:край',\n",
       " 'lem:сельскохозяйственный',\n",
       " 'word:или',\n",
       " 'lem:или',\n",
       " 'word:Крымского',\n",
       " 'word:района',\n",
       " 'word:Сумма',\n",
       " 'lem:сумма',\n",
       " 'word:Напомним',\n",
       " 'lem:напомнить',\n",
       " 'lem:инцидент',\n",
       " 'word:17',\n",
       " 'lem:17',\n",
       " 'lem:троицкий',\n",
       " 'word:Троицкой',\n",
       " 'word:Большого',\n",
       " 'lem:театр',\n",
       " 'word:театра',\n",
       " 'word:Сергей',\n",
       " 'lem:из',\n",
       " 'lem:больница',\n",
       " 'word:Москвы',\n",
       " 'Dmns',\n",
       " 'lem:–',\n",
       " 'word:–',\n",
       " 'punct_value:–',\n",
       " 'word:Германии',\n",
       " 'lem:германия',\n",
       " 'word:Участок',\n",
       " 'lem:дмитровка',\n",
       " 'lem:декабрь',\n",
       " 'lem:театральный',\n",
       " 'is_freq_театральный',\n",
       " 'is_key_проезд',\n",
       " 'lem:кузнецкий',\n",
       " 'word:Ранее',\n",
       " 'lem:ранее',\n",
       " 'word:США',\n",
       " 'lem:сша',\n",
       " 'word:против',\n",
       " 'lem:против',\n",
       " 'lem:ряд',\n",
       " 'lem:российский',\n",
       " 'lem:банк',\n",
       " 'word:Россия',\n",
       " 'lem:россия',\n",
       " 'lem:оператор',\n",
       " 'lem:председатель',\n",
       " 'lem:совет',\n",
       " 'lem:директор',\n",
       " 'word:Бориса',\n",
       " 'lem:борис',\n",
       " 'lem:известный',\n",
       " 'word:два',\n",
       " 'word:Олег',\n",
       " 'lem:олег',\n",
       " 'lem:компания',\n",
       " 'lem:известно',\n",
       " 'word:Андрей',\n",
       " 'lem:андрей',\n",
       " 'lem:рынок',\n",
       " 'lem:новорижский',\n",
       " 'Coll',\n",
       " 'lem:мужчина',\n",
       " 'lem:преступник',\n",
       " 'lem:суметь',\n",
       " 'lem:имя',\n",
       " 'word:им',\n",
       " 'lem:медицинский',\n",
       " 'lem:фигурант',\n",
       " 'lem:дело',\n",
       " 'is_freq_ленинский',\n",
       " 'lem:ленинский',\n",
       " 'word:Ленинском',\n",
       " 'lem:правление',\n",
       " 'lem:резонансный',\n",
       " 'lem:человек',\n",
       " 'lem:анатолий',\n",
       " 'lem:состав',\n",
       " 'lem:подмосковный',\n",
       " 'word:подмосковного',\n",
       " 'is_freq_город',\n",
       " 'is_key_город',\n",
       " 'places_pos_4',\n",
       " 'lem:жуковский',\n",
       " 'word:Жуковский',\n",
       " 'lem:войтюк',\n",
       " 'word:Войтюк',\n",
       " 'lem:решение',\n",
       " 'lem:строительство',\n",
       " 'lem:жилой',\n",
       " 'Prdx',\n",
       " 'lem:парк',\n",
       " 'word:Гарнаева',\n",
       " 'lem:гарнаева',\n",
       " 'word:администрации',\n",
       " 'lem:администрация',\n",
       " 'word:Евгений',\n",
       " 'lem:евгений',\n",
       " 'word:Садовая',\n",
       " 'lem:магазин',\n",
       " 'ANim',\n",
       " 'lem:создание',\n",
       " 'lem:ольга',\n",
       " 'word:ходе',\n",
       " 'lem:ход',\n",
       " 'lem:участник',\n",
       " 'word:Художественный',\n",
       " 'lem:художественный',\n",
       " 'lem:клуб',\n",
       " 'word:Владимира',\n",
       " 'lem:владимир',\n",
       " 'Arch',\n",
       " 'lem:детский',\n",
       " 'word:Н.',\n",
       " 'lem:наш',\n",
       " 'lem:весёлый',\n",
       " 'lem:изумрудный',\n",
       " 'word:Изумрудного',\n",
       " 'lem:цирк',\n",
       " 'lem:никулин',\n",
       " 'lem:цветной',\n",
       " 'is_freq_цветной',\n",
       " 'word:Цветном',\n",
       " 'lem:бульвар',\n",
       " 'is_freq_бульвар',\n",
       " 'lem:полный',\n",
       " 'lem:общество',\n",
       " 'word:Место',\n",
       " 'lem:место',\n",
       " 'word:Открытое',\n",
       " 'lem:открытый',\n",
       " 'lem:акционерный',\n",
       " 'word:общество',\n",
       " 'is_freq_год',\n",
       " 'word:г.',\n",
       " 'lem:санкт-петербург',\n",
       " 'word:Санкт-Петербург',\n",
       " 'lem:конституция',\n",
       " 'word:Конституции',\n",
       " 'word:д.',\n",
       " 'lem:далее',\n",
       " 'word:1',\n",
       " 'lem:1',\n",
       " 'lem:вид',\n",
       " 'lem:общий',\n",
       " 'lem:собрание',\n",
       " 'lem:годовой',\n",
       " 'word:Годовое',\n",
       " 'is_freq_победа',\n",
       " 'lem:адрес',\n",
       " 'word:Москва',\n",
       " 'word:ул',\n",
       " 'is_key_ул',\n",
       " 'lem:ул',\n",
       " 'word:дом',\n",
       " 'word:ОАО',\n",
       " 'lem:оао',\n",
       " 'word:Р.',\n",
       " 'lem:р',\n",
       " 'word:С.',\n",
       " 'lem:том',\n",
       " 'lem:;',\n",
       " 'word:;',\n",
       " 'punct_value:;',\n",
       " 'lem:васильевский',\n",
       " 'word:Васильевского',\n",
       " 'lem:отдел',\n",
       " 'lem:работа',\n",
       " 'lem:вопрос',\n",
       " 'lem:представитель',\n",
       " 'lem:основный',\n",
       " 'word:МРСК',\n",
       " 'lem:мрск',\n",
       " 'lem:необходимый',\n",
       " 'lem:другой',\n",
       " 'word:Московский',\n",
       " 'is_freq_московский',\n",
       " 'lem:московский',\n",
       " 'lem:сбербанк',\n",
       " 'word:России',\n",
       " 'lem:пять',\n",
       " 'lem:тимирязевский',\n",
       " 'word:Тимирязевская',\n",
       " 'word:Южнобутовская',\n",
       " 'lem:южнобутовский',\n",
       " 'word:б-р',\n",
       " 'lem:б-р',\n",
       " 'lem:башиловский',\n",
       " 'word:Башиловская',\n",
       " 'word:№',\n",
       " 'lem:№',\n",
       " 'lem:старое',\n",
       " 'word:площадь',\n",
       " 'lem:четыре',\n",
       " 'lem:свободный',\n",
       " 'word:Сбербанк',\n",
       " 'lem:зона',\n",
       " 'lem:телефон',\n",
       " 'lem:полиция',\n",
       " 'lem:электронный',\n",
       " 'lem:маршрут',\n",
       " 'word:Гоголя',\n",
       " 'lem:гоголь',\n",
       " 'word:Октябрьской',\n",
       " 'lem:октябрьский',\n",
       " 'lem:советский',\n",
       " 'word:Карла',\n",
       " 'lem:карл',\n",
       " 'word:Маркса',\n",
       " 'word:Маршрут',\n",
       " 'lem:музей',\n",
       " 'lem:современный',\n",
       " 'lem:искусство',\n",
       " 'word:Монастырская',\n",
       " 'lem:монастырский',\n",
       " 'lem:петропавловский',\n",
       " 'word:ул.',\n",
       " 'lem:ленин',\n",
       " 'word:Ленина',\n",
       " 'lem:гайдар',\n",
       " 'word:Гайдара',\n",
       " 'lem:локомотивный',\n",
       " 'word:Локомотивная',\n",
       " 'lem:энгельс',\n",
       " 'word:Энгельса',\n",
       " 'ways_pos_18',\n",
       " 'ways_pos_15',\n",
       " 'ways_pos_9',\n",
       " 'places_pos_11',\n",
       " 'ways_pos_12',\n",
       " 'is_key_ш',\n",
       " 'word:ш.',\n",
       " 'lem:ш',\n",
       " 'word:Космонавтов',\n",
       " 'lem:космонавт',\n",
       " 'word:Г.',\n",
       " 'lem:хасан',\n",
       " 'word:Хасана',\n",
       " 'word:далее',\n",
       " 'lem:б',\n",
       " 'word:Гагарина',\n",
       " 'lem:гагарин',\n",
       " 'lem:уральский',\n",
       " 'lem:крупский',\n",
       " 'word:Крупской',\n",
       " 'word:Дружбы',\n",
       " 'lem:дружба',\n",
       " 'word:Революции',\n",
       " 'lem:революция',\n",
       " 'word:Островского',\n",
       " 'lem:островский',\n",
       " 'word:М.',\n",
       " 'word:Горького',\n",
       " 'lem:горький',\n",
       " 'word:Пушкина',\n",
       " 'lem:пушкин',\n",
       " 'lem:октябрь',\n",
       " 'word:Октября',\n",
       " 'lem:сибирский',\n",
       " 'word:Сибирская',\n",
       " 'lem:белинский',\n",
       " 'word:Белинского',\n",
       " 'lem:комсомольский',\n",
       " 'is_freq_комсомольский',\n",
       " 'word:Комсомольская',\n",
       " 'word:Комсомольский',\n",
       " 'word:проспект',\n",
       " 'lem:пермский',\n",
       " 'word:Пермская',\n",
       " 'lem:екатерининский',\n",
       " 'lem:луначарский',\n",
       " 'word:Луначарского',\n",
       " 'lem:пр',\n",
       " 'word:пр',\n",
       " 'is_key_пр',\n",
       " 'lem:городской',\n",
       " 'lem:эспланада',\n",
       " 'word:эспланада',\n",
       " 'lem:памятник',\n",
       " 'Anum',\n",
       " 'lem:арбитражный',\n",
       " 'word:суд',\n",
       " 'lem:суд',\n",
       " 'word:Арбитражного',\n",
       " 'lem:март',\n",
       " 'lem:восток',\n",
       " 'word:Владимир',\n",
       " 'lem:станция',\n",
       " 'word:Славянский',\n",
       " 'word:бульвар',\n",
       " 'word:Парк',\n",
       " 'lem:медик',\n",
       " 'lem:три',\n",
       " 'lem:предварительный',\n",
       " 'lem:контактный',\n",
       " 'word:Максим',\n",
       " 'lem:максим',\n",
       " 'lem:уголовный',\n",
       " 'lem:президент',\n",
       " 'word:Путина',\n",
       " 'lem:путин',\n",
       " 'lem:метро',\n",
       " 'word:метро',\n",
       " 'lem:здание',\n",
       " 'word:здании',\n",
       " 'lem:школа',\n",
       " 'word:центре',\n",
       " 'lem:первое',\n",
       " 'word:Большая',\n",
       " 'word:здания',\n",
       " 'lem:всего',\n",
       " 'word:Всего',\n",
       " 'word:Мотовилихинском',\n",
       " 'lem:мотовилихинский',\n",
       " 'lem:пруд',\n",
       " 'word:пруду',\n",
       " 'is_freq_пруд',\n",
       " 'lem:верхний',\n",
       " 'word:Верхней',\n",
       " 'V-ej',\n",
       " 'lem:свердловский',\n",
       " 'lem:храм',\n",
       " 'lem:казанский',\n",
       " 'word:Казанской',\n",
       " 'lem:икона',\n",
       " 'word:Божьей',\n",
       " 'lem:божий',\n",
       " 'lem:пристанционный',\n",
       " 'word:Пристанционная',\n",
       " 'lem:традиционный',\n",
       " 'lem:житель',\n",
       " 'lem:пермь',\n",
       " 'word:Перми',\n",
       " 'lem:принять',\n",
       " 'lem:местный',\n",
       " 'lem:охрана',\n",
       " 'lem:сотрудник',\n",
       " 'lem:народный',\n",
       " 'lem:сейчас',\n",
       " 'lem:выбор',\n",
       " '2per',\n",
       " 'word:же',\n",
       " 'lem:же',\n",
       " 'lem:согласный',\n",
       " 'word:Навальный',\n",
       " 'lem:навальный',\n",
       " 'word:Михаила',\n",
       " 'lem:михаил',\n",
       " 'word:Жители',\n",
       " 'lem:кировский',\n",
       " 'word:кировского',\n",
       " 'lem:вятский',\n",
       " 'word:Вятские',\n",
       " 'is_freq_поляна',\n",
       " 'word:Поляны',\n",
       " 'lem:коммунальный',\n",
       " 'word:Киров',\n",
       " 'lem:киров',\n",
       " 'word:RU',\n",
       " 'lem:ru',\n",
       " 'word:Вятских',\n",
       " 'lem:третье',\n",
       " 'word:Кировской',\n",
       " 'lem:старый',\n",
       " 'lem:регион',\n",
       " 'lem:перекрёсток',\n",
       " 'lem:нижний',\n",
       " 'word:Нижнем',\n",
       " ...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.attributes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('PNCT', 'no'), 9.914438),\n",
       " (('is_freq_московский', 'CITY_TOWN'), 9.10397),\n",
       " (('w2v_19', 'CITY_TOWN'), 8.313187),\n",
       " (('w2v_291', 'CITY_TOWN'), 8.289856),\n",
       " (('PREP', 'no'), 7.796155),\n",
       " (('w2v_170', 'CITY_TOWN'), 7.528315),\n",
       " (('is_freq_московский', 'PUBLIC_ROAD'), 7.342685),\n",
       " (('CONJ', 'no'), 7.330513),\n",
       " (('w2v_291', 'PUBLIC_ROAD'), 6.825587),\n",
       " (('w2v_64', 'CITY_TOWN'), 6.606673),\n",
       " (('w2v_46', 'PUBLIC_ROAD'), 6.470935),\n",
       " (('w2v_122', 'CITY_TOWN'), 6.357505),\n",
       " (('w2v_116', 'CITY_TOWN'), 6.241968),\n",
       " (('w2v_34', 'CITY_TOWN'), 6.124438),\n",
       " (('w2v_49', 'CITY_TOWN'), 6.091447),\n",
       " (('is_freq_кремль', 'HOUSE_BLOCK'), 6.046871),\n",
       " (('w2v_74', 'CITY_TOWN'), 6.023019),\n",
       " (('ADVB', 'no'), 6.00771),\n",
       " (('ways_pos_2', 'HOUSE_BLOCK'), 5.916516),\n",
       " (('w2v_37', 'CITY_TOWN'), 5.890586),\n",
       " (('w2v_209', 'CITY_TOWN'), 5.860156),\n",
       " (('w2v_271', 'CITY_TOWN'), 5.857976),\n",
       " (('is_freq_ленинградский', 'CITY_TOWN'), 5.853622),\n",
       " (('w2v_46', 'CITY_TOWN'), 5.763661),\n",
       " (('w2v_10', 'CITY_TOWN'), 5.746648),\n",
       " (('lem:уфимский', 'CITY_TOWN'), 5.71989),\n",
       " (('is_freq_москва', 'CITY_TOWN'), 5.710874),\n",
       " (('lem:вятский', 'CITY_TOWN'), 5.689763),\n",
       " (('w2v_119', 'CITY_TOWN'), 5.687699),\n",
       " (('LATN', 'no'), 5.669129)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(crf.state_features_).most_common(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
